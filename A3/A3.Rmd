---
editor_options: 
  markdown: 
    wrap: 72
---

------------------------------------------------------------------------

title: "Assignment 3 - Finding fast growing firms" subtitle: "Course:
ECBS6067 - Prediction with Machine Learning for Economists" author:
"Anja Hahn, Teresa Huebel & Anne Valder" date: "2023-12-14" output:
pdf_document: default html_document: df_print: paged

# Summary

The goal of our analysis is to classify fast growing firms in order to
identify lucrative investment opportunities. This report includes three
different models to predict fast growing firms. It is based on bisnode
panel data. Firm growth is defined by average annual percentage growth
in sales over two years. We use data from 2012 to predict sales growth
two years ahead. The models are logit, random forest and logit lasso.
The models' predictive power is evaluated once without and once with the
use of a loss function. After the introduction of a loss function we
identified random forest as strongest model. This model is also used on
the subsets manufacturing and services In comparison, XXXX. Further
results and interactive graphs can be found in the shiny app linked to
this report.

{{< pagebreak >}}

```{r, include=FALSE}
# Clear memory
rm(list=ls())

# set global chunk options
knitr::opts_chunk$set(include = FALSE, fig.align = 'center', cache = TRUE,
                      warning = FALSE, message = FALSE, echo = FALSE)

options(scipen = 999)

```

```{r setup, include=FALSE}
# Set options for markdown
knitr::opts_knit$set(root.dir = 'C:/Users/avalder/OneDrive - WU Wien/Documents/Study/WS_23_24/Pred_MLE_Econ/da_case_studies')

# store different directories here:
# C:/Users/thuebel/OneDrive - WU Wien/Docs/06 Courses and Study/02 Prediction with ML for Economists/da_case_studies
# C:/Users/avalder/OneDrive - WU Wien/Documents/Study/WS_23_24/Pred_MLE_Econ/da_case_studies
# C:/Users/AnjaHahn/OneDrive - DataScience Service GmbH/WU/Courses/CEU Prediction with Machine Learning for Economists/da_case_studies

```

<!-- Set directory, load functions and theme  -->

```{r, include=FALSE}
#getwd()
source("set-data-directory.R")
source("ch00-tech-prep/theme_bg.R")
source("ch00-tech-prep/da_helper_functions.R")


data_in <- paste(data_dir,"bisnode-firms","clean/", sep = "/")
#use_case_dir <- "ch17-predicting-firm-exit/"

#set output directory
output <- "output/"

```

```{r,include=FALSE, warning=FALSE}
#load libraries
library(tidyverse)
library(caret)
library(ranger)
library(Hmisc)
library(knitr)
library(modelsummary)
library(treeshap)
library(summarytools)
library(pROC)
library(plotly)
# add
```

<!-- Load data  -->

```{r,include=FALSE}
bisnode <- read_csv(paste(data_in,"cs_bisnode_panel.csv", sep = "/")) # 287829 obs. of 48 variables 
```

<!-- Data summary  -->

```{r, include=FALSE}
# count missing values
colSums(is.na(bisnode))
colSums(is.na(bisnode))/nrow(bisnode)*100

#proportion of observations with less than 1 labor_avg among all that have an observation for labor_avg
bisnode %>% filter(labor_avg < 1) %>% nrow() / bisnode %>% filter(!is.na(labor_avg)) %>% nrow()

# look at data
bisnode %>% glimpse()

# look at character variables
bisnode %>%
  group_by(gender) %>%
  summarise(n = n(), mean = mean(sales))

# overall summary statistics
 #descr(bisnode)

```

## Sample Design

We exclude some variables that have extremely high rates of missing
values (above 90%) and only look at firms that are active in 2012, that
is, they have some sales. What is more, our analysis is only based on
firms with annual sales between 1000 and 10 million euros. We believe
this subset presents the most attractive investment opportunities.
First, very small firms with sales below 1000 EUR in sales are likely
not to seek investment and high growth events might happen at random
more easily. Second, very large firms are well represented in various
indices and any expected growth is likely to be already incorporated in
the stock price. Hence, our sample selection represents a business
decision to focus on a segment that is more predictable and more
promising for investors.

<!-- Sample design  -->

```{r, include=FALSE}
####################################
# Sample design
####################################
# collect "weird stuff" here:
# Company with ID 12212152320 had a massive explosion from 2012 to 2013 (0 to 63 employees etc) - how to treat?
## did they exit before? Maybe we have to add a variable that indicate newly established firms?

# add all missing year and company combinations
bisnode <- bisnode %>%
  complete(year, comp_id)

# drop variables with many NAs
bisnode <- bisnode %>%        
  select(-c(COGS, finished_prod, net_dom_sales, net_exp_sales, wages, D))

# find the years with the least missing sales values
bisnode %>%
  group_by(year) %>%
  summarise(missing = sum(is.na(sales))) %>%
  arrange(missing)
# biggest sample would be 2013-2014
# NAs of all variables per year 
bisnode %>%
  group_by(year) %>%
  summarise(across(everything(), ~ mean(is.na(.)) * 100, .names = "na_share_{.col}")) %>%
  ungroup()

# generate status_alive, we only want to analyse active firms
bisnode  <- bisnode %>%
  mutate(status_alive = sales > 0 & !is.na(sales) %>%
           as.numeric(.))

# look at cross section
# add explanation to report!!!!
bisnode <- bisnode %>%
  filter(status_alive == TRUE) %>% # only look at firms that have some sales
  # look at firms below 10m euro revenues and above 1000 euros
  filter(!(sales > 10000000)) %>%
  filter(!(sales < 1000))

```

<!-- Data visualization  -->

```{r, include=FALSE}
# visualize sales
plot_sales <-  ggplot(bisnode, aes(x = sales)) +
  geom_histogram(bins = 100, fill = color[1], color = color.outline, alpha = 0.8) +
  scale_x_log10() +
  labs(x = "Sales (log)", y = "Frequency")+
  theme_bg() 
plot_sales

# visualize labor_avg
plot_labor_avg <- bisnode %>% filter(labor_avg > 0) %>%
  ggplot(aes(x = labor_avg)) +
  geom_histogram(bins = 100, fill = color[1], color = color.outline, alpha = 0.8) +
  labs(x = "Average Number of Employees", y = "Frequency") +
  xlim(0, 5) +
    theme_bg() 
plot_labor_avg


```

## Label Engineering

We are exploring multiple alternatives as target variable to represent
high growth firms. In our selection we pay attention to the following
dimensions: i) the indicator to choose, ii) the measurement, iii) the
time horizon, and iv) the threshold. The literature does not yield one
consensus over a definition of high growth firms, it rather points out
that any decision along these dimensions depends on the goal of the
analysis.[\^1] We decided for relative average annual sales growth over
two years for the following reasons: First, sales provided a more
relevant and reliable target than number of employees. Sales data is
missing only in 2.6% of cases whereas number of employees is missing in
50.9% of cases. Also, sales growth is more closely linked to higher
profits. What is more, 85% of firms had less than 1 employee on average.
Second, we decided to use relative growth instead of absolute growth.
This decision will favor smaller firms since high relative growth is
harder to achieve for larger firms. We believe relative growth to be
more relevant since it is more closely linked to our expected return on
investment. To be more specific, we calculated percentage change and did
not rely on log differences. Even though this decision does not affect
the ranking of firms, it does affect the magnitude of the growth rate in
the subset of high growth firms. We favored percentage change because of
its more intuitive interpretation. Third, we decided for a two year time
horizon instead of a one year horizon to relate more closely to the OECD
definition of high growth firms that is defined over a three year
horizon. Third, we decided for a threshold of 30% annual growth. In our
sample this is equivalent to classifying roughly the fastest growing 20%
of firms as HGF. In the literature, both thresholds on a certain growth
rates and a certain percentile of firms are used. We decided for a
threshold based on a specific growth rates since we want to analyze
different sectors (manufacturing and services) with a fixed benchmark.

[\^1] Alex Coad, Sven-Olov Daunfeldt, Werner Hölzl, Dan Johansson, Paul
Nightingale, High-growth firms: introduction to the special section,
Industrial and Corporate Change, Volume 23, Issue 1, February 2014,
Pages 91--112, <https://doi.org/10.1093/icc/dtt052>

<!-- Label engineering  -->

```{r, include=FALSE}
####################################
# Label engineering
####################################

# generate different variations to display sales
bisnode <- bisnode %>%
  filter(status_alive == TRUE) %>% # only look at firms that have some sales
  mutate(ln_sales = log(sales), # if we want to include firms not_alive need to specially treat 0
         sales_mil=sales/1000000,
         sales_mil_log = ifelse(sales > 0, log(sales_mil), 0))
# this already windsorizes sales

# generate different variations to display labor_avg
bisnode <- bisnode %>%
  mutate(ln_labor_avg = ifelse(labor_avg > 0, log(labor_avg), 0))

###################################
# Creation of different labels: sales
###################################

# YoY relative sales growth
bisnode <- bisnode %>%
  group_by(comp_id) %>%
  arrange(year) %>%
  mutate(sales_growth_ahead = (lead(sales)/sales -1)) %>%
  ungroup()

# YoY sales growth as logdiff
bisnode <- bisnode %>%
  group_by(comp_id) %>%
  arrange(year) %>%
  mutate(d1_sales_mil_log = lead(sales_mil_log) - sales_mil_log ) %>%
  ungroup()

# 2-year ahead average annual sales growth as percentage change
# our target!!!
bisnode <- bisnode %>%
  group_by(comp_id) %>%
  arrange(year) %>%
  mutate(sales_growth_2y_ahead = (lead(sales, n = 2L)/sales -1)/2) %>%
  ungroup()

###################################
# Visualization sales growth

# make histogram that shows both sales growth and d1_sales_mil_log
plot_sales_growth_both <- ggplot(bisnode, aes(x = sales_growth_ahead)) +
  geom_histogram(aes(fill = "Percentage Change"), bins = 100, color = color.outline, alpha = 0.5) +
  geom_histogram(aes(x = d1_sales_mil_log, fill = "Log-Differences"), bins = 100, 
                 color = color.outline, alpha = 0.5) +
  scale_x_log10() +
  labs(x = "Sales growth (log)", y = "Frequency") +
  scale_fill_manual(values = c("Percentage Change" = color[1], "Log-Differences" = color[2]), 
                    name = "Growth Measures") +
  theme_bg()

plot_sales_growth_both
# It makes a difference whether relative growth is measured in log(diff) or percentage change
# since logdiff is an inaccurate approximation for high changes this is especially relevant for high growth firms

###################################
# Creation of different labels: employment
###################################
# important note: employee variables are now calculated based on lag variabes not lead variables
# hence, we can use them as features instead of target

# YoY relative employee growth
bisnode <- bisnode %>%
  group_by(comp_id) %>%
  arrange(year) %>%
  mutate(labor_growth = (labor_avg/lag(labor_avg) - 1)) %>%
  ungroup()

# YoY employee growth as logdiff
bisnode <- bisnode %>%
  group_by(comp_id) %>%
  arrange(year) %>%
  mutate(d1_labor_avg_log = ln_labor_avg - lag(ln_labor_avg) ) %>%
  ungroup()

# birch index (weighted index of absolute and relative employment growth)
bisnode <- bisnode %>%
  group_by(comp_id) %>%
  arrange(year) %>%
  mutate(birch_ind = ((labor_avg - lag(labor_avg)) * (labor_avg/lag(labor_avg) - 1)) ) %>%
  ungroup()

###################################
# Visualization employment growth

#make histogram that shows both employee growth and d1_labor_avg_log
plot_labor_growth_both <- ggplot(bisnode, aes(x = labor_growth)) +
  geom_histogram(aes(fill = "Percentage Change"), bins = 100, color = color.outline, alpha = 0.5) +
  geom_histogram(aes(x = d1_labor_avg_log, fill = "Log-Differences"), bins = 100, 
                 color = color.outline, alpha = 0.5) +
  labs(x = "Employee growth (log)", y = "Frequency") +
  scale_fill_manual(values = c("Percentage Change" = color[1], "Log-Differences" = color[2]), 
                    name = "Growth Measures") +
  scale_x_log10() #+
  # theme_bg()
plot_labor_growth_both

# make histogram of birch index
plot_birch_ind <- ggplot(bisnode, aes(x = birch_ind)) +
  geom_histogram(bins = 100, fill = color[1], color = color.outline, alpha = 0.8) +
  labs(x = "Birch Index", y = "Frequency") +
  theme_bg() +
  scale_x_log10()
plot_birch_ind


###################################
# Overwrite d1_sales_mil log to lagged variables since we will not use it as target but might include it as predictor
# YoY sales growth as logdiff
bisnode <- bisnode %>%
  group_by(comp_id) %>%
  arrange(year) %>%
  mutate(d1_sales_mil_log = sales_mil_log - lag(sales_mil_log) ) %>%
  ungroup()


# show the number of NA in the variable growth_2y_ahead for each year
x <-bisnode %>%
  group_by(year) %>%
  summarise(na_count = sum(is.na(sales_growth_2y_ahead)))


###################################
# Define Cutoff for High Growth firms
###################################

# Look at good cutoff for high growth
quantile(bisnode$sales_growth_2y_ahead, na.rm = TRUE, probs = seq(0, 1, 0.05))

# define high growth firms as firms that grow with more than 30% (coincides with fastest 20% in our data set)
bisnode <- bisnode %>%
  mutate(high_growth = ifelse(sales_growth_2y_ahead > 0.3, 1, 0)) %>%
  # code NA as 0 since these firms have no sales data/below 1000 sales
  # even if the missing values don't mean the firm exited, they are unlikely to be high growth
  # we want to avoid false positives and excluding them would be a bigger issue!
  mutate(high_growth = ifelse(is.na(high_growth), 0, high_growth))
# TARGET VARIABLE: high_growth

# add factor variant of high_growth
bisnode$high_growth_factor <- as.factor(ifelse(bisnode$high_growth == 1, "high_growth", "low_growth"))
# order levels such that low_growth is first (this way it will be used as control in the roc function to determine the loss)
bisnode$high_growth_factor <- factor(bisnode$high_growth_factor, levels = c("low_growth", "high_growth"))


####################################
# notes on growth
####################################
# different types of growth
# yoy relative growth in sales
# average yoy relative growth in sales over 2 years
# yoy relative growth in employees
# average yoy relative growth in employees over 2 years

# cutoff:
# classify as "fast" if they meet a combination of the above?
# OECD definition: 20% average growth in sales or employees over 3 years
# do the same but only with 2 years? Anne: sounds good and justified to me!

# in literature it has been suggested to use fastest growing percintile 8e.g. to 5% of firms)
# see: https://www.diva-portal.org/smash/get/diva2:605658/FULLTEXT01.pdf
# rather than hard cutoff --> but not meaningful for us if we want to compare growth in different industries
# a lot of firms with 0-1 employees: might need a lower absolute threshold for growth such that tiny firms that
# add one extra employee are not classified as fast growing?
```

\^23 <!-- Filter for 2012  -->

```{r}
# restrict sample to 2012 for further analysis

bisnode <- bisnode %>%
  filter(year == 2012)

```

## Feature Engineering

Feature engineering of the bisnode data set comprises re-coding of
existing variables s.t. they get the appropriate class and/or meaningful
levels and values. Also, plausibility checks are conducted: As some of
our financial variables (e.g. *inventories*, *fixed_assets* etc.) must
not be negative, we flag them and set negative values to zero. Other
implausible variables, such as *ceo_age* below 18 years, we set to NA.

In the process of analysing missing values, we impute some important
ones (*ceo_age*, *labor_avg*) and add flags for missing values. For
other, very important variables (mainly on assets, ceo and industry
information), we do not impute but rather drop missing values. Moreover,
we intend to use the variable on previous firm growth as predictor for
(future) fast growth -- very much in the same fashion as we know from
time trend models. Thus, we include the lagged growth in sales (2011 to
2012). As this results in some NAs (due to some missing sales values in
2011), we again flag the observations concerned and impute them by
replacing them with 0. This means we assume that said observations did
not experience any growth. Although this solution is not ideal, it is
based on the assumption that we compare a firm's (missing) sales value
in 2011 to the value of its "nearest neighbour" -- the firm's sales in
2012.

Moreover, we compute some new variables: *age* of the company, a dummy
for whether it is a *new* company, has *multiple_ceo*s, a
*foreign_management*. We classify the observations based on their
two-digit NACE codes into "manufacturing" vs. "services" (*ind2_cat*
variable), generate a variable for *total_assets* and compute ratios of
some financial variables (with either *total_assets* or *sales* as
reference). Lastly, we windsorize tails of numeric variables and add
flags accordingly.

<!-- Feature engineering  -->

```{r, include=FALSE}
# re-code one character variable
bisnode <- bisnode %>%
  mutate(urban_m = case_when(
      urban_m == 1 ~ "capital_city",
      urban_m == 2 ~ "other_big_city",
      urban_m == 3 ~ "other"))

# convert character variables to factors 
bisnode <- bisnode %>% 
  mutate_if(is.character, as.factor)

# classify industry categories as factors
bisnode <- bisnode %>%
  mutate(across(all_of(c("ind", "ind2", "nace_main")), as.factor))

###################################
# new variables
# firm characteristics
bisnode <- bisnode %>%
  mutate(age = (year-founded_year) %>% # maybe remove again if computed earlier
           ifelse(. < 0, 0, .),
         age_quad = age^2,
         new = as.numeric(age <= 1),
         foreign_management = as.numeric(foreign >= 0.5),
         multiple_ceo = as.numeric(ceo_count > 1),
         ceo_age = (year-round(birth_year))) # avoid digits for years

###################################
# plausibility checks of relevant numeric variables
for (var in c("age", "ceo_age", "ceo_count", "tang_assets",
             "curr_assets", "curr_liab", "extra_exp", "extra_inc",
             "extra_profit_loss", "fixed_assets", "inc_bef_tax",
             "intang_assets", "inventories", "liq_assets", "material_exp",
             "personnel_exp", "profit_loss_year", "share_eq", "subscribed_cap")){
  print(paste(paste0(var, 
                     ": min:", 
                     min(bisnode[, var], na.rm = TRUE), 
                     "; max:"),
              max(bisnode[, var], na.rm = TRUE)))
}
rm(var)

###################################
# problematic data
# age CEO cannot be negative, also some too young
bisnode <- bisnode %>%
  mutate(ceo_age = ifelse(ceo_age < 18, NA, ceo_age)) # overwrite implausible ones with NA for now

# there cannot be negative financial variables
zero <- c("curr_liab", "curr_assets", "extra_exp", "extra_inc", "fixed_assets",
          "intang_assets", "inventories", "liq_assets", "material_exp",
          "personnel_exp", "subscribed_cap", "tang_assets")

# flag negative ones
for (var in zero){
  aux <- paste0(var, "_flag_error")
  bisnode[, aux] <- as.numeric(bisnode[, var] < 0)
}

# flag any negative assets 
# (extra variable for calculating total assets later)
bisnode <- bisnode %>%
  mutate(flag_asset_problem = ifelse(intang_assets < 0 | curr_assets < 0 | fixed_assets < 0, 1, 0))

# set negative ones to zeros
bisnode <- bisnode %>%
  mutate_at(vars(zero), funs(ifelse(. < 0, 0, .)))


###################################
# NA analysis and imputation
colSums(is.na(bisnode))/nrow(bisnode)*100

# drop missing important variables
# drops about 20%
bisnode <- bisnode %>%
  filter(!is.na(liq_assets), # representative of missing assets data
         !is.na(foreign), # representative of missing CEO data
         !is.na(ind), # representative of industry data (removes many NACE 2-digit categories)
         !is.na(region_m), # geographical info
         !is.na(age),
         !is.na(material_exp)) 


# impute important ones
# ceo age
bisnode <- bisnode %>%
  mutate(flag_missing_ceo_age = as.numeric(is.na(ceo_age)),
         ceo_age = round(ifelse(is.na(ceo_age), mean(ceo_age, na.rm = TRUE), ceo_age)))

# number of employees
bisnode <- bisnode %>%
  mutate(flag_miss_labor_avg = as.numeric(is.na(labor_avg)),
         labor_avg = ifelse(is.na(labor_avg), mean(labor_avg, na.rm = TRUE), labor_avg))

# overwrite ln_labor_avg with imputed values
bisnode <- bisnode %>%
  mutate(ln_labor_avg = ifelse(labor_avg > 0, log(labor_avg), 0))

# impute d1_sales_mil_log as zero growth and create a flag
bisnode <- bisnode %>%
  mutate(flag_missing_d1_sales_mil_log = as.numeric(is.na(d1_sales_mil_log)),
         d1_sales_mil_log = ifelse(is.na(d1_sales_mil_log), 0, d1_sales_mil_log))


# still existing NAs

for (var in names(bisnode)){
  
  if(any(is.na(bisnode[, var]))){
    print(paste0(var, ":", sum(is.na(bisnode[, var]))/nrow(bisnode)*100))
  }
}
rm(var)

###################################
# new variables and 
# variable transformation

# group some industry category codes (2-digit NACE)
# after NA removal, categories have decreased considerably to
# manufactoring and services industries
table(bisnode$ind2)
bisnode <- bisnode %>%
  mutate(ind2_cat = factor(case_when(
    ind2 %in% c("26", "27", "28", "29", "30", "33") ~ "manufacturing",
    ind2 %in% c("55", "56") ~ "services"
  )))

# calculate new age ceo variable
bisnode <- bisnode %>%
  mutate(ceo_young = as.numeric(ceo_age < 40 & !is.na(ceo_age)),
         ceo_old = as.numeric(ceo_age > 75 & !is.na(ceo_age)))

# generate total assets
bisnode <- bisnode %>%
  mutate(total_assets = intang_assets + curr_assets + fixed_assets)

# compute relative variables (sales as reference)
bisnode <- bisnode %>%
  mutate_at(vars("extra_exp", "extra_inc", "extra_profit_loss", 
                 "inc_bef_tax", "inventories", "material_exp",
                 "profit_loss_year", "personnel_exp"),
            funs("rel" = ./sales))

# compute relative variables (total assets as reference)
bisnode <- bisnode %>%
  mutate_at(vars("intang_assets", "curr_liab", "fixed_assets", 
                 "liq_assets", "curr_assets", "share_eq", 
                 "subscribed_cap", "tang_assets"),
            funs("rel" = ifelse(total_assets == 0, 0, ./total_assets)))


######################################
# creating flags and winsorizing tails

# overwrite selected variables with relative ones
zero <- paste0(zero, "_rel")

# flag very high observations and set them to 1
bisnode <- bisnode %>%
  mutate_at(vars(zero), funs("flag_high"= as.numeric(. > 1))) %>%
  mutate_at(vars(zero), funs(ifelse(. > 1, 1, .)))

# for vars that could be any (also negative), but are mostly between -1 and 1
any <-  c("extra_profit_loss_rel", "inc_bef_tax_rel", "profit_loss_year_rel", "share_eq_rel")

# add flags and set tails to -1/1 and add quadratics
bisnode <- bisnode %>%
  mutate_at(vars(any), funs("flag_low" = as.numeric(. < -1))) %>%
  mutate_at(vars(any), funs(ifelse(. < -1, -1, .))) %>%
  mutate_at(vars(any), funs("flag_high" = as.numeric(. > 1))) %>%
  mutate_at(vars(any), funs(ifelse(. > 1, 1, .))) %>%
  mutate_at(vars(any), funs("flag_zero" = as.numeric(. == 0))) %>%
  mutate_at(vars(any), funs("quad" = .^2))

# dropping flags with no variation
variances <- bisnode %>%
  select(contains("flag")) %>%
  apply(2, var, na.rm = TRUE) == 0
bisnode <- bisnode %>%
  select(-one_of(names(variances)[variances]))

# sales
bisnode <- bisnode %>%
  mutate(sales_mil_log_quad = sales_mil_log^2)

bisnode <- bisnode %>%
  mutate(flag_low_d1_sales_mil_log = ifelse(d1_sales_mil_log < -1.5, 1, 0),
         flag_high_d1_sales_mil_log = ifelse(d1_sales_mil_log > 1.5, 1, 0),
         d1_sales_mil_log_mod = ifelse(d1_sales_mil_log < -1.5, -1.5,
                                       ifelse(d1_sales_mil_log > 1.5, 1.5, d1_sales_mil_log)),
         d1_sales_mil_log_mod_quad = d1_sales_mil_log_mod^2
         )

```

Next, we look at relationships between predictors and the binary
response. We use the LOESS (locally estimated scatterplot smoothing)
method to fit a smooth curve to the data points. In case the curve shows
some clear non-linear behaviour, we add quadratic terms of predictors
concerned. These decisions are re-assured by the estimation of simple
GLMs, where we explain *high_growth* with the respective numeric
variable and its quadratic -- whenever we detect a statistically
significant relationship between a quadratic term and the binary
response, we add that variable as quadratic predictor as well. From
visual inspection of the plots, we can say that in general, asset
variables do not show a lot of variation in the response i.e. do not
seem to affect *fast_growth* as much.

```{r variable_relations}
########################################
# relationships between variables

# scatterplot computation
plots <- list()

# relevant numeric vars
vars_num <- c(zero, any, c("total_assets", "ceo_age", "age", "labor_avg", "ln_labor_avg",
                           "sales_mil", "sales_mil_log", "d1_sales_mil_log_mod",
                           "d1_sales_mil_log_mod_quad"))

# check relationships
for (var in vars_num){
  
  if(any(is.na(bisnode[, var]))){
    print(paste0(var, " entails NAs")) # check for lowess
  } else{
    plots[[var]] <- ggplot(data = bisnode, aes_string(x = var, y = "high_growth")) +
  geom_point(size = 1, fill = color[2], color = color[2]) +
  geom_smooth(method = "loess", se = F, colour = color[1], size = 1.5, span = 0.9) +
  theme_bg()
  }
}

# plots to show
# example of adding quadratic
plots$ceo_age
# example of not adding quadratic
plots$curr_assets_rel

# check lm with quadratics
glm_results <- list()

for (var in vars_num){
  
  # build the formula dynamically
  formula <- formula(paste0("high_growth ~ ", var, " + I(", var, "^2)"))
  
  glm <- glm(formula, data = bisnode, family = "binomial")
  glm_results[[var]] <- summary(glm)
  
}



```

Moreover, we looked at the relationship between the binary response and
binary/categorical predictors. In the plot below, we see, for example,
that *high_growth* seems to be more prevalent with a young (defined as
\< 40 years) CEO. Also, a firm being very young (\< 1 age) seems to play
a role. As regards possible interactions, the below plot hints towards a
relationship between industry category (NACE 2 digit classification) and
age of the company, as can be seen by the different slopes of the fitted
line per category.

```{r variable_relations_2}
# add quadratics for chosen variables (based on plots and glms)
quad <- c("intang_assets_rel", "inventories_rel", "liq_assets_rel", "material_exp_rel",
          "personnel_exp_rel", "subscribed_cap_rel", "inc_bef_tax_rel", 
          "profit_loss_year_rel", "share_eq_rel", "total_assets", "ceo_age", "extra_profit_loss_rel")

bisnode <- bisnode %>%
  mutate_at(vars(quad), funs("quad"= .^2))


# response vs. binary and factor variables
binary_variables <- c("gender", "origin", "ind2", "ind", "ind2_cat", "urban_m",
                      "region_m", "ceo_old", "ceo_young")


# two examples
ggplot(bisnode, aes(x = factor(new), fill = factor(high_growth))) +
  geom_bar(position = "fill", stat = "count") +
  labs(y = "Proportion", fill = "High Growth") +
  theme_bg() +
  scale_fill_manual(values = c(color[1], color[2])) +
  theme(legend.text = element_text(size = 10))
ggplot(bisnode, aes(x = factor(ceo_young), fill = factor(high_growth))) +
  geom_bar(position = "fill", stat = "count") +
  labs(y = "Proportion", fill = "High Growth") +
  theme_bg() +
  scale_fill_manual(values = c(color[1], color[2])) +
  theme(legend.text = element_text(size = 10))

# interactions
ggplot(bisnode, aes(x = age, y = high_growth, color = ind2)) +
  # ggplot(bisnode, aes(x = age, y = high_growth, color = ind2_cat)) +
  theme_bw() + 
  geom_point() + 
  geom_point(alpha = .3, 
             size = .9) +
  geom_smooth(method = "lm") #+ 
  # scale_color_manual(values = c(color[1], color[2]))

# drop unused factor levels
bisnode <- bisnode %>%
  mutate(across(where(is.factor), ~ droplevels(.)))

# check remaining data
colSums(is.na(bisnode))/nrow(bisnode)*100
# datasummary_skim(bisnode, type='numeric', histogram = TRUE)


```

## Variable Selection

#### Logit Model

For the logit, we try out two specifications. Both of them include the
sales variables (past growth), engineered variables (i.e. ratios of
financial variables, windsorized), the detected (possible) quadratic
terms and the flags we created for extreme, missing and potentially
erroneous data. Also, both specifications include quality variables
(balance sheet information) and information on HR (e.g. CEO information)
and the firm itself (e.g. regarding the location and industry). The
difference lies in interactions included: Whilst the first specification
does not include any interactions, the second one interacts selected
variables with the industry variable. The first model entails **81**
terms and the second one entails **90** terms.

#### Probability Forest

Since the probability forest can deal with complicated relationships
between variables, we do not include any quadratics, interacted,
modified and/or windsorized variables. Thus, the raw financial, quality,
sales, HR and firm variables are added. Also, potentially highly
correlated variables are considered together. Categorical variables are
encoded as factors. This gives us **49** variables.

#### LASSO Logit

For the LASSO logit, we consider the same variables as in the second
logit specification (including one additional highly correlated
variable). This yields in total 91 vars.

<!-- Task1.1: Define variable groups for differnet models  -->

```{r}
#####################
# Group Variables

# # one-hot encode factor variables (to use in random forest and later for SHAP values)
# variable_types <- sapply(bisnode, class)
# # Identify factor variables
# factor_variables <- names(variable_types[variable_types == "factor"])
# 
# dmy <- dummyVars("~ ind + ind2 + ind2_cat + gender + origin + region_m + urban_m", 
#                  data = bisnode, fullRank = TRUE)
# new_dat <- data.frame(predict(dmy, newdata = bisnode))
# # add new variables to data
# bisnode <- cbind(bisnode, new_dat)
# rm(new_dat)

rawvars <-  c("curr_assets", "curr_liab", "extra_exp", "extra_inc", "extra_profit_loss", 
              "fixed_assets", "inc_bef_tax", "intang_assets", "inventories", "liq_assets", 
              "material_exp", "personnel_exp", "profit_loss_year", "share_eq", "subscribed_cap")

qualityvars <- c("balsheet_flag", "balsheet_length", "balsheet_notfullyear")

engvar <- c("total_assets", "fixed_assets_rel", "liq_assets_rel", "curr_assets_rel",
            "share_eq_rel", "subscribed_cap_rel", "intang_assets_rel", "extra_exp_rel",
            "extra_inc_rel", "extra_profit_loss_rel", "inc_bef_tax_rel", "inventories_rel",
            "material_exp_rel", "profit_loss_year_rel", "personnel_exp_rel", 
            "curr_liab_rel")

engvar2 <- c(grep("*quad", names(bisnode), value = TRUE))
engvar2 <- engvar2[engvar2 != "sales_mil_log_quad"]

engvar3 <- c(grep("*flag_low$", names(bisnode), value = TRUE),
             grep("*flag_high$", names(bisnode), value = TRUE),
             grep("*flag_error$", names(bisnode), value = TRUE),
             grep("*flag_zero$", names(bisnode), value = TRUE))
# do not add flag_assets_problem due to missing variation
# add two variables not grepled before
engvar3 <- c(engvar3, c("flag_low_d1_sales_mil_log", "flag_high_d1_sales_mil_log"))

sales <-  c(#"sales_mil_log", # no flag for NA because there are none for sales_mil
            "d1_sales_mil_log_mod", 
            "flag_missing_d1_sales_mil_log")

hr <- c("ceo_old", "ceo_young", "ceo_age", "flag_missing_ceo_age", 
        "gender", "multiple_ceo", "origin", # have origin instead of foreign_management
        "ln_labor_avg", "flag_miss_labor_avg")

firm <- c("age", "new", "urban_m", "region_m", "ind2")

#onehot <- names(bisnode[, c(133:150)])

# test <- c(rawvars, qualityvars, engvar, engvar2, engvar3, sales, hr, firm)
# setdiff(names(bisnode), test);setdiff(test, names(bisnode))

# interactions for logit, LASSO
interactions1 <- c("ind2*age", "ind2*age_quad",
                   "ind2*d1_sales_mil_log_mod", 
                   #"ind2*sales_mil_log", 
                   "ind2*ceo_age", "ind2*origin", "ind2*gender",
                   "ind2*urban_m", "ind2*ln_labor_avg", "ind2*multiple_ceo")

# interactions2 <- c("sales_mil_log*age", "sales_mil_log*gender",
                   # "sales_mil_log*profit_loss_year_rel", "sales_mil_log*origin",
                   # "sales_mil_log*multiple_ceo")

####################
# Variable Selection

# logit
# try without interactions?
logitvars1 <- c(qualityvars, engvar, engvar2, engvar3, sales, hr, firm)
length(logitvars1)
logitvars2 <- c(qualityvars, engvar, engvar2, engvar3, sales, hr, firm, interactions1)
length(logitvars2)
logit_model_vars <- list("logit_no_interactions" = logitvars1, "logit_incl_interactions" = logitvars2)

# caret always (no matter if all sales vars excluded or not) gives warnings: 
# Angepasste Wahrscheinlichkeiten mit numerischem Wert 0 oder 1 aufgetreten
# Warnung: Vorhersage durch Fit ohne vollen Rang mag täuschen
# below works with d1_sales_mil_log variables
# below does not work with sales_mil_log variables
# below shows no warnings on multicollinearity
# also, Gabor's code shows warnings: Vorhersage durch Fit ohne vollen Rang mag täuschen
# idea: exclude sales_mil_log variables and ignore warnings
# glm_1 <- glm(formula(paste0("high_growth_factor ~", paste0(logitvars1, collapse = " + "))),
#              family = "binomial",
#              data = bisnode_work)

# summary(glm_1)

# random forest (no interactions, no modified features)
rfvars  <-  c("d1_sales_mil_log", "flag_missing_d1_sales_mil_log", 
              "ceo_count", "labor_avg", rawvars, qualityvars, hr, firm)
# rfvars  <-  c("d1_sales_mil_log", "flag_missing_d1_sales_mil_log", 
#               "ceo_count", "labor_avg", rawvars, qualityvars, hr, firm, onehot)
#rfvars <- rfvars[!rfvars %in% c("origin", "gender", "urban_m", "region_m", "ind2")]

length(rfvars)
# for logit LASSO
lassovars <- c("ceo_count", qualityvars, engvar, engvar2, engvar3, sales, hr, firm, interactions1)
length(lassovars)

```

<!-- Preparation for prediction & CV  -->

```{r,include=FALSE}
set.seed(123456)

# create work and holdout
work_indices <- as.integer(createDataPartition(bisnode$high_growth, p = 0.8, list = FALSE))
bisnode_work <- bisnode[work_indices, ]
bisnode_holdout <- bisnode[-work_indices, ]

dim(bisnode_work)
dim(bisnode_holdout)

# separation into train and test automatically via cross-validation using caret package

n_folds = 5
train_control <- trainControl(method = "cv",
                              number = n_folds,
                              classProbs = TRUE, # computing probabilities during training
                              summaryFunction = twoClassSummaryExtended, 
                              savePredictions = TRUE, # fromda_helper_functions.R
      
                              verboseIter = TRUE)


```

## Model Estimation

We divide our data set into a work (80 percent, 15,229 observations) and
holdout set (20 percent, 3,807 observations). The workout set will be
used to train our models. We use 5-fold cross validation to evaluate
performance of our models.

<!-- Task1.1: Model 1 - Logit  -->

```{r}
#######################################################
# PART I PREDICT PROBABILITIES
# Predict logit model ----------------------------------------------
#######################################################

# No loss function
# RMSE (AUC also?based on threshold that corresponds to prevalence of pos/neg in dataset)

# Train Logit Models ----------------------------------------------
## keep maybe for shiny but decide which is our main model!

CV_RMSE_folds <- list()
logit_models <- list()

for (model_name in names(logit_model_vars)) {

  features <- logit_model_vars[[model_name]]

  set.seed(13505)
  glm_model <- train(
    formula(paste0("high_growth_factor ~", paste0(features, collapse = " + "))),
    method = "glm",
    data = bisnode_work,
    family = binomial,
    trControl = train_control
  )

  logit_models[[model_name]] <- glm_model
  # Calculate RMSE on test for each fold
  CV_RMSE_folds[[model_name]] <- glm_model$resample[, c("Resample", "RMSE")]

}


#############################################x
# PART I
# No loss fn
########################################

# Draw ROC Curve and calculate AUC for each folds --------------------------------
CV_AUC_folds <- list()

for (model_name in names(logit_models)) {

  auc <- list()
  model <- logit_models[[model_name]]
  for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
    cv_fold <-
      model$pred %>%
      filter(Resample == fold)

    roc_obj <- roc(cv_fold$obs, cv_fold$high_growth)
    auc[[fold]] <- as.numeric(roc_obj$auc)
  }

  CV_AUC_folds[[model_name]] <- data.frame("Resample" = names(auc),
                                              "AUC" = unlist(auc))
}

# For each model: average RMSE and average AUC for models ----------------------------------

CV_RMSE <- list()
CV_AUC <- list()

for (model_name in names(logit_models)) {
  CV_RMSE[[model_name]] <- mean(CV_RMSE_folds[[model_name]]$RMSE)
  CV_AUC[[model_name]] <- mean(CV_AUC_folds[[model_name]]$AUC)
}

# # Take best model and estimate RMSE on holdout  -------------------------------------------
# 
# best_logit_no_loss <- logit_models[["logit_no_interactions"]]
# 
# logit_predicted_probabilities_holdout <- predict(best_logit_no_loss, newdata = bisnode_holdout, type = "prob")
# bisnode_holdout[,"best_logit_no_loss_pred"] <- logit_predicted_probabilities_holdout[,"high_growth"]
# RMSE(bisnode_holdout[, "best_logit_no_loss_pred", drop=TRUE], bisnode_holdout$high_growth)

```

<!-- Task1.1: Model 2 - Probability forest  -->

```{r}
#################################################
# Probability forest
# Split by gini, ratio of 1's in each tree, average over trees
#################################################

tune_grid <- expand.grid(
  .mtry = c(5, 6, 7), # sq root is 6.244
  .splitrule = "gini",
  .min.node.size = c(10, 15))

# getModelInfo("ranger")
rf_model_p <- train(
  formula(paste0("high_growth_factor ~ ", paste0(rfvars , collapse = " + "))),
  method = "ranger",
  data = bisnode_work,
  tuneGrid = tune_grid,
  trControl = train_control,
  importance = "impurity"
)

rf_model_p$results

best_mtry <- rf_model_p$bestTune$mtry
best_min_node_size <- rf_model_p$bestTune$min.node.size

# Get average (ie over the folds) RMSE and AUC ------------------------------------
CV_RMSE_folds[["rf_p"]] <- rf_model_p$resample[,c("Resample", "RMSE")]

auc <- list()
for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
  cv_fold <-
    rf_model_p$pred %>%
    filter(Resample == fold)

  roc_obj <- roc(cv_fold$obs, cv_fold$high_growth)
  auc[[fold]] <- as.numeric(roc_obj$auc)
}
CV_AUC_folds[["rf_p"]] <- data.frame("Resample" = names(auc),
                                         "AUC" = unlist(auc))

CV_RMSE[["rf_p"]] <- mean(CV_RMSE_folds[["rf_p"]]$RMSE)
CV_AUC[["rf_p"]] <- mean(CV_AUC_folds[["rf_p"]]$AUC)

```

<!-- Task1.1: Model 3 - Logit LASSO  -->

```{r}
# Logit lasso -----------------------------------------------------------

lambda <- 10^seq(-1, -4, length = 10)
grid <- expand.grid("alpha" = 1, lambda = lambda)

system.time({
  logit_lasso_model <- train(
    formula(paste0("high_growth_factor ~", paste0(lassovars, collapse = " + "))),
    data = bisnode_work,
    method = "glmnet",
    preProcess = c("center", "scale"),
    family = "binomial",
    trControl = train_control,
    tuneGrid = grid,
    na.action=na.exclude
  )
})

tuned_logit_lasso_model <- logit_lasso_model$finalModel
best_lambda <- logit_lasso_model$bestTune$lambda
logit_models[["LASSO"]] <- logit_lasso_model
lasso_coeffs <- as.matrix(coef(tuned_logit_lasso_model, best_lambda))

CV_RMSE_folds[["LASSO"]] <- logit_lasso_model$resample[,c("Resample", "RMSE")]

# AUC
auc <- list()
for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
  cv_fold <-
    logit_lasso_model$pred %>%
    filter(Resample == fold)

  roc_obj <- roc(cv_fold$obs, cv_fold$high_growth)
  auc[[fold]] <- as.numeric(roc_obj$auc)
}
CV_AUC_folds[["LASSO"]] <- data.frame("Resample" = names(auc),
                                      "AUC" = unlist(auc))

CV_RMSE[["LASSO"]] <- mean(CV_RMSE_folds[["LASSO"]]$RMSE)
CV_AUC[["LASSO"]] <- mean(CV_AUC_folds[["LASSO"]]$AUC)

```

### Probability Prediction

The below plot shows the results for our different model specifications.
We would choose the first simple logit model over the second, since it
has fewer coefficients and even better (lower) RMSE and (higher) AUC.
The logit LASSO does not perform better, either (worse AUC and similar
RMSE). Based on the CV results, we would therefore go for the random
forest which performs slightly better in both the RMSE and AUC.

```{r summary_no_loss}

ncoeff <- lapply(logit_models, FUN = function(x) length(x$coefnames))
ncoeff[["rf"]] <- NA
nvars <- list()
nvars[["logit_no_interactions"]] <- length(logitvars1[-grep("quad", logitvars1)])
nvars[["logit_incl_interactions"]] <- length(logitvars2[-grep("quad|\\*", logitvars2)]) # same as above
nvars[["LASSO"]] <- length(lassovars[-grep("quad|\\*", logitvars2)])
nvars[["rf"]] <- length(rfvars)

summary_no_loss <- data.frame(Model = c("Logit w/o interactions", "Logit w interactions", "Logit LASSO", "Random Forest"),
                              Preds = c(nvars$logit_no_interactions, nvars$logit_incl_interactions, nvars$LASSO, nvars$rf),
                              Coeffs = c(ncoeff$logit_no_interactions, ncoeff$logit_incl_interactions, ncoeff$LASSO, ncoeff$rf),
                              RMSE = c(CV_RMSE$logit_no_interactions, CV_RMSE$logit_incl_interactions, CV_RMSE$LASSO, CV_RMSE$rf_p),
                              AUC = c(CV_AUC$logit_no_interactions, CV_AUC$logit_incl_interactions, CV_AUC$LASSO, CV_AUC$rf_p))

kable(x = summary_no_loss, format = "latex", booktabs = TRUE,  digits = 3, row.names = TRUE,
      linesep = "")

```

We use our best model to predict on the holdout set and receive a RMSE
of **0.372**. Also, we produce the below (discrete) ROC plot which shows
us the trade off between making false positive and false negative
errors. The confusion matrices for default classification (using 0.5 as
threshold) and for the threshold set to the mean of predicted values
(approx. 0.2) show, as expected, how a lower threshold would lead to a
higher probability of predicting high growth. Also, we nicely see the
trade-off between false positives (going up) and false negatives (going
down) when lowering the threshold. However, these choices of thresholds
are still not based on a proper loss function, to which we will come
next.

```{r best_model_no_loss}

# Take best model and estimate RMSE on holdout
# Take model to holdout and estimate RMSE, AUC and expected loss ------------------------------------

rf_predicted_probabilities_holdout <- predict(rf_model_p, newdata = bisnode_holdout, type = "prob")
bisnode_holdout$rf_p_prediction <- rf_predicted_probabilities_holdout[,"high_growth"]
RMSE(bisnode_holdout$rf_p_prediction, bisnode_holdout$high_growth)

# produce ROC plot (discrete; could also be continuous)
thresholds <- seq(0.05, 0.75, by = 0.05)
cm <- list()
true_positive_rates <- c()
false_positive_rates <- c()
for (thr in thresholds) {
  holdout_prediction <- ifelse(bisnode_holdout[,"rf_p_prediction"] < thr, "low_growth", "high_growth") %>%
    factor(levels = c("low_growth", "high_growth"))
  cm_thr <- confusionMatrix(holdout_prediction, bisnode_holdout$high_growth_factor)$table
  cm[[as.character(thr)]] <- cm_thr
  true_positive_rates <- c(true_positive_rates, cm_thr["high_growth", "high_growth"] /
                             (cm_thr["high_growth", "high_growth"] + cm_thr["low_growth", "high_growth"]))
  false_positive_rates <- c(false_positive_rates, cm_thr["high_growth", "low_growth"] /
                              (cm_thr["high_growth", "low_growth"] + cm_thr["low_growth", "low_growth"]))
}

tpr_fpr_for_thresholds <- tibble(
  "threshold" = thresholds,
  "true_positive_rate" = true_positive_rates,
  "false_positive_rate" = false_positive_rates
)

discrete_roc_plot <- ggplot(
  data = tpr_fpr_for_thresholds,
  aes(x = false_positive_rate, y = true_positive_rate, color = threshold)) +
  labs(x = "False positive rate (1 - Specificity)", y = "True positive rate (Sensitivity)") +
  geom_point(size=2, alpha=0.8) +
  #scale_color_viridis(option = "D", direction = -1) +
  scale_x_continuous(expand = c(0.01,0.01), limit=c(0,1), breaks = seq(0,1,0.1)) +
  scale_y_continuous(expand = c(0.01,0.01), limit=c(0,1), breaks = seq(0,1,0.1)) +
  theme_bg() +
  theme(legend.position ="right") +
  theme(legend.title = element_text(size = 4), 
        legend.text = element_text(size = 4),
        legend.key.size = unit(.4, "cm")) 
discrete_roc_plot

# do classification with "random" threshold
# default: the threshold 0.5 is used to convert probabilities to binary classes
rf_class_prediction <- predict(rf_model_p, newdata = bisnode_holdout)
summary(rf_class_prediction)

# confusion matrix for 0.5 threshold
cm_object1 <- confusionMatrix(rf_class_prediction, bisnode_holdout$high_growth_factor, positive = "high_growth")
cm1 <- cm_object1$table
cm1

# observations in holdout
obs_holdout <- nrow(bisnode_holdout)

# add a version of the table where each cell is divided by the total number of observations
cm1_perc <- cm1/obs_holdout

# add column and row totals
cm1_perc <- cbind(cm1_perc, rowSums(cm1_perc))
cm1_perc <- rbind(cm1_perc, colSums(cm1_perc))

# add missing row and column names
cm1_perc <- as.data.frame(cm1_perc)
colnames(cm1_perc) <- c("Actual Low Growth", "Actual High Growth", "Total")
rownames(cm1_perc) <- c("Predicted Low Growth", "Predicted High Growth", "Total")

# multiply each with 100 and add %
cm1_perc[] <- lapply(cm1_perc, function(x) sprintf("%.2f%%", x * 100))

kable(x = cm1_perc, format = "latex", booktabs = TRUE,  digits = 3, row.names = TRUE,
      linesep = "")


# confusion matrix for mean of predicted probabilities
mean_predicted_highgrowth_prob <- mean(bisnode_holdout$rf_p_prediction)
holdout_prediction <-
  ifelse(bisnode_holdout$rf_p_prediction < mean_predicted_highgrowth_prob, "low_growth", "high_growth") %>%
  factor(levels = c("low_growth", "high_growth"))
cm_object2 <- confusionMatrix(holdout_prediction, bisnode_holdout$high_growth_factor)
cm2 <- cm_object2$table
cm2

# add a version of the table where each cell is divided by the total number of observations
cm2_perc <- cm2/obs_holdout

# add column and row totals
cm2_perc <- cbind(cm2_perc, rowSums(cm2_perc))
cm2_perc <- rbind(cm2_perc, colSums(cm2_perc))

# add missing row and column names
cm2_perc <- as.data.frame(cm2_perc)
colnames(cm2_perc) <- c("Actual Low Growth", "Actual High Growth", "Total")
rownames(cm2_perc) <- c("Predicted Low Growth", "Predicted High Growth", "Total")

# multiply each with 100 and add %
cm2_perc[] <- lapply(cm2_perc, function(x) sprintf("%.2f%%", x * 100))

kable(x = cm2_perc, format = "latex", booktabs = TRUE,  digits = 3, row.names = TRUE,
      linesep = "")


```

<!-- Task1.1: Evaluation  -->

```{r}
# discrete ROC (with thresholds in steps) on holdout -------------------------------------------------
# continuous ROC on holdout with best model (Logit 4) -------------------------------------------
# Confusion table with different thresholds ----------------------------------------------------------
# Calibration curve -----------------------------------------------------------

# Create table that compares models based on RMSE and AUC and also shows number of predictors and number of coefficients




## ADD
```

## Introduction of Loss Function

Next, we introduce a loss function specifically tailored for our business case. In selecting the best model, our primary objective is to minimize false positives. This is crucial because we aim to avoid investing in firms that do not exhibit strong growth potential. However, there's a challenge: only 20% of firms in our dataset are categorized as fast-growing. Overemphasizing the cost of false positives could inadvertently lead the model to classify all observations as low growth. Such an approach would undermine our goal of identifying high-potential business opportunities.

To address this, we have calibrated the cost associated with false positives (FP) and false negatives (FN) in a balanced manner. We have set the cost of a false positive at 150% of that of a false negative. This ratio reflects a strategic decision: while avoiding unfruitful investments is important, we also don't want to miss out on promising firms. Additionally, we have incorporated the prevalence of high-growth firms into the model's weighting system. This adjustment ensures that our model remains sensitive to the relatively scarce yet valuable high-growth opportunities in our dataset, thereby aligning the model's predictions more closely with our business objectives.

<!-- Task1.2: Loss function design -->

```{r}
#############################################
# PART II.
# We have a loss function
########################################

# Introduce loss function
# relative cost of of a false negative classification (as compared with a false positive classification)
FP= 1.5
FN= 1
cost = FN/FP
# the prevalence, or the proportion of cases in the population (n.cases/(n.controls+n.cases))
prevalence = sum(bisnode_work$high_growth)/length(bisnode_work$high_growth)

# Draw ROC Curve and find optimal threshold with loss function --------------------------
```

```{r}

# incorporate loss function for logit models
best_tresholds <- list()
expected_loss <- list()
logit_cv_rocs <- list()
logit_cv_threshold <- list()
logit_cv_expected_loss <- list()

for (model_name in names(logit_models)) {

  model <- logit_models[[model_name]]
  colname <- paste0(model_name,"_prediction")

  best_tresholds_cv <- list()
  expected_loss_cv <- list()

  for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
    cv_fold <-
      model$pred %>%
      filter(Resample == fold)
    
    # Check if length(cv_fold$high_growth) is zero
    if (length(cv_fold$high_growth) == 0) {
      print(paste("Warning: length of high_growth in", fold, "of model", model_name, "is zero."))
      next  # Skip to the next iteration
    }

    roc_obj <- roc(cv_fold$obs, cv_fold$high_growth)
    best_treshold <- coords(roc_obj, "best", ret="all", transpose = FALSE,
                            best.method="youden", best.weights=c(cost, prevalence))
    best_tresholds_cv[[fold]] <- best_treshold$threshold
    expected_loss_cv[[fold]] <- (best_treshold$fp*FP + best_treshold$fn*FN)/length(cv_fold$high_growth)
  }

  # average
  best_tresholds[[model_name]] <- mean(unlist(best_tresholds_cv))
  expected_loss[[model_name]] <- mean(unlist(expected_loss_cv))

  # for fold #5
  logit_cv_rocs[[model_name]] <- roc_obj
  logit_cv_threshold[[model_name]] <- best_treshold
  logit_cv_expected_loss[[model_name]] <- expected_loss_cv[[fold]]

}

###############################################
logit_summary <- data.frame("Avg of optimal thresholds" = unlist(best_tresholds),
                             "Threshold for Fold5" = sapply(logit_cv_threshold, function(x) {x$threshold}),
                             "Avg expected loss" = unlist(expected_loss),
                             "Expected loss for Fold5" = unlist(logit_cv_expected_loss))

kable(x = logit_summary, format = "latex", booktabs=TRUE,  digits = 3, row.names = TRUE,
      linesep = "", col.names = c("Avg of optimal thresholds","Threshold for fold #5",
                                  "Avg expected loss","Expected loss for fold #5"))

## Create plots based on Fold5 in CV ----------------------------------------------
## below loop does not run!!!
 for (model_name in names(logit_cv_rocs)) {

   r <- logit_cv_rocs[[model_name]]
   best_coords <- logit_cv_threshold[[model_name]]
   createLossPlot(r, best_coords,
                  paste0(model_name, "_loss_plot"))
   createRocPlotWithOptimal(r, best_coords,
                            paste0(model_name, "_roc_plot"))
 }


# Pick best model based on average expected loss ----------------------------------

best_logit_with_loss <- logit_models[["logit_incl_interactions"]]
best_logit_optimal_treshold <- best_tresholds[["logit_incl_interactions"]]

logit_predicted_probabilities_holdout <- predict(best_logit_with_loss, newdata = bisnode_holdout, type = "prob")
bisnode_holdout[,"best_logit_with_loss_pred"] <- logit_predicted_probabilities_holdout[,"high_growth"]

# ROC curve on holdout
roc_obj_holdout <- roc(bisnode_holdout$high_growth, bisnode_holdout[, "best_logit_with_loss_pred", drop=TRUE])

# Get expected loss on holdout
holdout_treshold <- coords(roc_obj_holdout, x = best_logit_optimal_treshold, input= "threshold",
                           ret="all", transpose = FALSE)
expected_loss_holdout <- (holdout_treshold$fp*FP + holdout_treshold$fn*FN)/length(bisnode_holdout$high_growth)
expected_loss_holdout

# Confusion table on holdout with optimal threshold
holdout_prediction <-
  ifelse(bisnode_holdout$best_logit_with_loss_pred < best_logit_optimal_treshold, "low_growth", "high_growth") %>%
  factor(levels = c("low_growth", "high_growth"))
cm_object3 <- confusionMatrix(holdout_prediction,bisnode_holdout$high_growth_factor)
cm3 <- cm_object3$table
cm3

```

<!-- Task1.1: Loss function RF -->

```{r}
################################
# loss function for RF
################################

# Now use loss function and search for best thresholds and expected loss over folds -----
best_tresholds_cv <- list()
expected_loss_cv <- list()

for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
  cv_fold <-
    rf_model_p$pred %>%
    filter(mtry == best_mtry,
           min.node.size == best_min_node_size,
           Resample == fold)

  roc_obj <- roc(cv_fold$obs, cv_fold$high_growth)
  best_treshold <- coords(roc_obj, "best", ret="all", transpose = FALSE,
                          best.method="youden", best.weights=c(cost, prevalence))
  best_tresholds_cv[[fold]] <- best_treshold$threshold
  expected_loss_cv[[fold]] <- (best_treshold$fp*FP + best_treshold$fn*FN)/length(cv_fold$high_growth)
}

# average
best_tresholds[["rf_p"]] <- mean(unlist(best_tresholds_cv))
expected_loss[["rf_p"]] <- mean(unlist(expected_loss_cv))


# display RF performance
rf_summary <- data.frame("CV RMSE" = CV_RMSE[["rf_p"]],
                         "CV AUC" = CV_AUC[["rf_p"]],
                         "Avg of optimal thresholds" = best_tresholds[["rf_p"]],
                         "Threshold for Fold5" = best_treshold$threshold,
                         "Avg expected loss" = expected_loss[["rf_p"]],
                         "Expected loss for Fold5" = expected_loss_cv[[fold]])

kable(x = rf_summary, format = "latex", booktabs=TRUE,  digits = 3, row.names = TRUE,
      linesep = "", col.names = c("CV RMSE", "CV AUC",
                                  "Avg of optimal thresholds","Threshold for fold #5",
                                  "Avg expected loss","Expected loss for fold #5"))


# Create plots - this is for Fold5
# below functions do not run!!!
createLossPlot(roc_obj, best_treshold, "rf_p_loss_plot")
createRocPlotWithOptimal(roc_obj, best_treshold, "rf_p_roc_plot")

# Take model to holdout and estimate RMSE, AUC and expected loss ------------------------------------

rf_predicted_probabilities_holdout <- predict(rf_model_p, newdata = bisnode_holdout, type = "prob")
bisnode_holdout$rf_p_prediction <- rf_predicted_probabilities_holdout[,"high_growth"]
RMSE(bisnode_holdout$rf_p_prediction, bisnode_holdout$high_growth)

# ROC curve on holdout
roc_obj_holdout <- roc(bisnode_holdout$high_growth_factor, bisnode_holdout[, "rf_p_prediction", drop=TRUE])

# AUC
as.numeric(roc_obj_holdout$auc)

# Get expected loss on holdout with optimal threshold
holdout_treshold <- coords(roc_obj_holdout, x = best_tresholds[["rf_p"]] , input= "threshold",
                           ret="all", transpose = FALSE)
expected_loss_holdout <- (holdout_treshold$fp*FP + holdout_treshold$fn*FN)/length(bisnode_holdout$high_growth)
expected_loss_holdout
```

## Model Comparison with Loss Function
After the introduction of our loss function, we can now compare the models based on their average expected loss over all folds. The model with the lowest expected loss is still the random forest. The simple logistic regression without interactions has the second lowest expected loss.


<!-- Task1.2: For each of the three models: predict probabilities, look for the optimal classification threshold, calculate expected loss with your loss function  -->

<!-- Task1.2: Pick model with smallest expected loss -->

```{r}
# compare all models: to pick the one with lowest expected loss
###############################################

summary_all_mods <- data.frame(Model = c("Logit w/o interactions", "Logit w interactions", 
                                         "Logit LASSO", "Random Forest"),
                              Preds = c(nvars$logit_no_interactions, 
                                        nvars$logit_incl_interactions, nvars$LASSO, nvars$rf),
                              Coeffs = c(ncoeff$logit_no_interactions, 
                                         ncoeff$logit_incl_interactions, ncoeff$LASSO, ncoeff$rf),
                              RMSE = c(CV_RMSE$logit_no_interactions, 
                                       CV_RMSE$logit_incl_interactions, CV_RMSE$LASSO, CV_RMSE$rf_p),
                              AUC = c(CV_AUC$logit_no_interactions, 
                                      CV_AUC$logit_incl_interactions, CV_AUC$LASSO, CV_AUC$rf_p),
                              threshold = c(best_tresholds$logit_no_interactions,
                                            best_tresholds$logit_incl_interactions, 
                                            best_tresholds$LASSO, best_tresholds$rf_p),
                              exp_loss = c(expected_loss$logit_no_interactions,
                                           expected_loss$logit_incl_interactions, 
                                           expected_loss$LASSO, expected_loss$rf_p))

kable(x = summary_all_mods, format = "latex", booktabs=TRUE,  digits = 3, row.names = TRUE,
      linesep = "", col.names = c("Model", "Predictors", "Coefficients", "CV RMSE", "CV AUC",
                                  "CV threshold", "CV expected Loss"))


```

## Confusion Table
The confusion table shows that we have an accuracy of 82.03% on the holdout set. The model only predicts 1.65% of models to have high growth whereas the prevalence of high growth firms in the data is 18.57%. This low sensitivity (6%) is necessary in order to arrive at the high specificity (99.3%) we desire. This is a trade off we are willing to engage in, in order to avoid investing in firms that will not outperform the market or might even go bankrupt. If we apply our model to similar datasets in multiple countries we will still arrive at a reasonably large number of predicted high growth firms such that our portfolio will be diversified. 

Of course, we realize that we could not test the external validity of our model and applying it in other countries migth lead to worse performance. To that end we conduct another exercise and apply our model to different market segments, that is, manufacturing and services.


<!-- Task1.3: Show a confusion table (on a selected fold or holdout set) -->

<!-- Task1.3: Discuss results, evaluate how useful your model may be -->

```{r}
###############################################
# Create Confusion table for the RF model
###############################################
# Confusion table on holdout for RF
holdout_prediction <-
  ifelse(bisnode_holdout$rf_p_prediction < best_tresholds[["rf_p"]], "low_growth", "high_growth") %>%
  factor(levels = c("low_growth", "high_growth"))
cm_object4 <- confusionMatrix(holdout_prediction,bisnode_holdout$high_growth_factor)
cm4 <- cm_object4$table

# observations in holdout
obs_holdout <- nrow(bisnode_holdout)

# add a version of the table where each cell is divided by the total number of observations
cm4_perc <- cm4/obs_holdout

# add column and row totals
cm4_perc <- cbind(cm4_perc, rowSums(cm4_perc))
cm4_perc <- rbind(cm4_perc, colSums(cm4_perc))

# add missing row and column names
cm4_perc <- as.data.frame(cm4_perc)
colnames(cm4_perc) <- c("Actual Low Growth", "Actual High Growth", "Total")
rownames(cm4_perc) <- c("Predicted Low Growth", "Predicted High Growth", "Total")

# multiply each with 100 and add %
cm4_perc[] <- lapply(cm4_perc, function(x) sprintf("%.2f%%", x * 100))

kable(x = cm4_perc, format = "latex", booktabs = TRUE,  digits = 3, row.names = TRUE,
      linesep = "")

```

<!-- Task2.1: 2 Samples (service & manufacturing)  -->

```{r}
# work sets for the two sub samples 
manu_work <- bisnode_work %>% filter(ind2_cat == "manufacturing")
serv_work <- bisnode_work %>% filter(ind2_cat == "services")

# holdout sets for the two sub samples 
manu_holdout <- bisnode_work %>% filter(ind2_cat == "manufacturing")
serv_holdout <- bisnode_work %>% filter(ind2_cat == "services")
```

<!-- Task2.1: 2 Samples (service & manufacturing) Random forest (WITHOUT LOSS FUNCTION!!!)  -->

```{r}
#################################################
# Probability forest for manufacturing sample!
# Split by gini, ratio of 1's in each tree, average over trees
#################################################

rf_model_p_manu <- train(
  formula(paste0("high_growth_factor ~ ", paste0(rfvars , collapse = " + "))),
  method = "ranger",
  data = manu_work,
  tuneGrid = tune_grid,
  trControl = train_control,
  importance = "impurity"
)

rf_model_p_manu$results

best_mtry <- rf_model_p_manu$bestTune$mtry
best_min_node_size <- rf_model_p_manu$bestTune$min.node.size

# Get average (ie over the folds) RMSE and AUC ------------------------------------
CV_RMSE_folds[["rf_p_manu"]] <- rf_model_p_manu$resample[,c("Resample", "RMSE")]

auc <- list()
for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
  cv_fold <-
    rf_model_p_manu$pred %>%
    filter(Resample == fold)

  roc_obj <- roc(cv_fold$obs, cv_fold$high_growth)
  auc[[fold]] <- as.numeric(roc_obj$auc)
}
CV_AUC_folds[["rf_p_manu"]] <- data.frame("Resample" = names(auc),
                                         "AUC" = unlist(auc))

CV_RMSE[["rf_p_manu"]] <- mean(CV_RMSE_folds[["rf_p_manu"]]$RMSE)
CV_AUC[["rf_p_manu"]] <- mean(CV_AUC_folds[["rf_p_manu"]]$AUC)



```

```{r}
######################################
# loss function for RF manufacturing
######################################

# Now use loss function and search for best thresholds and expected loss over folds -----
best_tresholds_cv_manu <- list()
expected_loss_cv_manu <- list()

for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
  cv_fold <-
    rf_model_p_manu$pred %>%
    filter(mtry == best_mtry,
           min.node.size == best_min_node_size,
           Resample == fold)

  roc_obj <- roc(cv_fold$obs, cv_fold$high_growth)
  best_treshold <- coords(roc_obj, "best", ret="all", transpose = FALSE,
                          best.method="youden", best.weights=c(cost, prevalence))
  best_tresholds_cv_manu[[fold]] <- best_treshold$threshold
  expected_loss_cv_manu[[fold]] <- (best_treshold$fp*FP + best_treshold$fn*FN)/length(cv_fold$high_growth)
}

# average
best_tresholds[["rf_p_manu"]] <- mean(unlist(best_tresholds_cv_manu))
expected_loss[["rf_p_manu"]] <- mean(unlist(expected_loss_cv_manu))


# display RF performance
rf_summary_manu <- data.frame("CV RMSE" = CV_RMSE[["rf_p_manu"]],
                         "CV AUC" = CV_AUC[["rf_p_manu"]],
                         "Avg of optimal thresholds" = best_tresholds[["rf_p_manu"]],
                         "Threshold for Fold5" = best_treshold$threshold,
                         "Avg expected loss" = expected_loss[["rf_p_manu"]],
                         "Expected loss for Fold5" = expected_loss_cv[[fold]])

kable(x = rf_summary_manu, format = "latex", booktabs=TRUE,  digits = 3, row.names = TRUE,
      linesep = "", col.names = c("CV RMSE", "CV AUC",
                                  "Avg of optimal thresholds","Threshold for fold #5",
                                  "Avg expected loss","Expected loss for fold #5"))


# Create plots - this is for Fold5
# below function do not run!!!
createLossPlot(roc_obj, best_treshold, "rf_p_manu_loss_plot")
createRocPlotWithOptimal(roc_obj, best_treshold, "rf_p_manu_roc_plot")

# Take model to holdout and estimate RMSE, AUC and expected loss ------------------------------------

rf_predicted_probabilities_manu_holdout <- predict(rf_model_p_manu, newdata = manu_holdout, type = "prob")
manu_holdout$rf_p_manu_prediction <- rf_predicted_probabilities_manu_holdout[,"high_growth"]
RMSE(manu_holdout$rf_p_manu_prediction, manu_holdout$high_growth)

# ROC curve on holdout
roc_obj_manu_holdout <- roc(manu_holdout$high_growth_factor, manu_holdout[, "rf_p_manu_prediction", drop=TRUE])

# AUC
as.numeric(roc_obj_manu_holdout$auc)

# Get expected loss on holdout with optimal threshold
holdout_treshold_manu <- coords(roc_obj_manu_holdout, x = best_tresholds[["rf_p_manu"]] , input= "threshold",
                           ret="all", transpose = FALSE)
expected_loss_holdout_manu <- (holdout_treshold$fp*FP + holdout_treshold$fn*FN)/length(manu_holdout$high_growth)
#expected_loss_holdout_manu
```

```{r}
#################################################
# Probability forest for service sample!
# Split by gini, ratio of 1's in each tree, average over trees
#################################################

rf_model_p_serv <- train(
  formula(paste0("high_growth_factor ~ ", paste0(rfvars , collapse = " + "))),
  method = "ranger",
  data = serv_work,
  tuneGrid = tune_grid,
  trControl = train_control,
  importance = "impurity"
)

rf_model_p_serv$results

best_mtry <- rf_model_p_serv$bestTune$mtry
best_min_node_size <- rf_model_p_serv$bestTune$min.node.size

# Get average (ie over the folds) RMSE and AUC ------------------------------------
CV_RMSE_folds[["rf_p_serv"]] <- rf_model_p_serv$resample[,c("Resample", "RMSE")]

auc <- list()
for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
  cv_fold <-
    rf_model_p_serv$pred %>%
    filter(Resample == fold)

  roc_obj <- roc(cv_fold$obs, cv_fold$high_growth)
  auc[[fold]] <- as.numeric(roc_obj$auc)
}
CV_AUC_folds[["rf_p_serv"]] <- data.frame("Resample" = names(auc),
                                         "AUC" = unlist(auc))

CV_RMSE[["rf_p_serv"]] <- mean(CV_RMSE_folds[["rf_p_serv"]]$RMSE)
CV_AUC[["rf_p_serv"]] <- mean(CV_AUC_folds[["rf_p_serv"]]$AUC)

```

```{r}
######################################
# loss function for RF services
######################################

# Now use loss function and search for best thresholds and expected loss over folds -----
best_tresholds_cv_serv <- list()
expected_loss_cv_serv <- list()

for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
  cv_fold <-
    rf_model_p_serv$pred %>%
    filter(mtry == best_mtry,
           min.node.size == best_min_node_size,
           Resample == fold)

  roc_obj <- roc(cv_fold$obs, cv_fold$high_growth)
  best_treshold <- coords(roc_obj, "best", ret="all", transpose = FALSE,
                          best.method="youden", best.weights=c(cost, prevalence))
  best_tresholds_cv_serv[[fold]] <- best_treshold$threshold
  expected_loss_cv_serv[[fold]] <- (best_treshold$fp*FP + best_treshold$fn*FN)/length(cv_fold$high_growth)
}

# average
best_tresholds[["rf_p_serv"]] <- mean(unlist(best_tresholds_cv_serv))
expected_loss[["rf_p_serv"]] <- mean(unlist(expected_loss_cv_serv))


# display RF performance
rf_summary_serv <- data.frame("CV RMSE" = CV_RMSE[["rf_p_serv"]],
                         "CV AUC" = CV_AUC[["rf_p_serv"]],
                         "Avg of optimal thresholds" = best_tresholds[["rf_p_serv"]],
                         "Threshold for Fold5" = best_treshold$threshold,
                         "Avg expected loss" = expected_loss[["rf_p_serv"]],
                         "Expected loss for Fold5" = expected_loss_cv[[fold]])

kable(x = rf_summary_serv, format = "latex", booktabs=TRUE,  digits = 3, row.names = TRUE,
      linesep = "", col.names = c("CV RMSE", "CV AUC",
                                  "Avg of optimal thresholds","Threshold for fold #5",
                                  "Avg expected loss","Expected loss for fold #5"))


# Create plots - this is for Fold5
# below functions do not run!!
createLossPlot(roc_obj, best_treshold, "rf_p_serv_loss_plot")
createRocPlotWithOptimal(roc_obj, best_treshold, "rf_p_serv_roc_plot")

# Take model to holdout and estimate RMSE, AUC and expected loss ------------------------------------

rf_predicted_probabilities_serv_holdout <- predict(rf_model_p_serv, newdata = serv_holdout, type = "prob")
serv_holdout$rf_p_serv_prediction <- rf_predicted_probabilities_serv_holdout[,"high_growth"]
RMSE(serv_holdout$rf_p_serv_prediction, serv_holdout$high_growth)

# ROC curve on holdout
roc_obj_serv_holdout <- roc(serv_holdout$high_growth_factor, serv_holdout[, "rf_p_serv_prediction", drop=TRUE])

# AUC
as.numeric(roc_obj_serv_holdout$auc)

# Get expected loss on holdout with optimal threshold
holdout_treshold_serv <- coords(roc_obj_serv_holdout, x = best_tresholds[["rf_p_serv"]] , input= "threshold",
                           ret="all", transpose = FALSE)
expected_loss_holdout_serv <- (holdout_treshold$fp*FP + holdout_treshold$fn*FN)/length(serv_holdout$high_growth)
#expected_loss_holdout_serv
```

### Comparison of models in manufacturing and services
The random forest performs better in the services sector. It exhibits a lower RMSE, a higher AUC and a lower expected loss. More differences can be seen in the respective confusion tables. First, manufacturing exhibits a higher prevalence of high growth firms (20.6% versus 17.6%). The mode

In both subsets our random forest exhibits similar performance. Interestingly RMSE, AUC and expected loss are all identical up to three digits. The optimal threshold is somewhat lower in the services subset. This already hints at the more profound difference between the samples that we can see in the confusion matrices. Even though expected losses are identical, they are not identically distributed over false positives and false negatives. First, it should be noted that the prevalence of high growth firms is lower in the services sector (17.6%) than in the manufacturing sector (20.6%). Second, the model is much more cautious in predicting high growth in the services sector. Here only 4.5% of all firms are predicted as high growth compared to 14.4% in manufacturing. Still, the false positive rate is lower in manufacturing. It seems to be the case that it is easier to avoid predicting false positives in this subset. Hence, the model can arrive at a rate of positive predictions that is closer to the prevalence in the data.  

<!-- Task2.3: Compare the model performance across two samples -->

```{r}

# make table with RMSE, AUC, and expected loss for both subsets

# compare all models: to pick the one with lowest expected loss
###############################################

summary_manu_serv <- data.frame(Model = c("Manufacturing", "Services"),
                              RMSE = c(CV_RMSE$rf_p_manu, 
                                       CV_RMSE$rf_p_serv),
                              AUC = c(CV_AUC$rf_p_manu, 
                                      CV_AUC$rf_p_serv),
                              threshold = c(best_tresholds$rf_p_manu,
                                            best_tresholds$rf_p_serv),
                              exp_loss = c(expected_loss$rf_p_manu,
                                           expected_loss$rf_p_serv))
# identical loss, different thresholds used look at CM to interpret this

kable(x = summary_manu_serv, format = "latex", booktabs=TRUE,  digits = 3, row.names = TRUE,
      linesep = "", col.names = c("Model", "CV RMSE", "CV AUC",
                                  "CV threshold", "CV expected Loss"))

###############################################
# make confusion table for both subsets

# Confusion table on holdout manufacturing
holdout_pred_manu <-
  ifelse(manu_holdout$rf_p_manu_prediction < best_tresholds[["rf_p_manu"]], "low_growth", "high_growth") %>%
  factor(levels = c("low_growth", "high_growth"))
cm_object5 <- confusionMatrix(holdout_pred_manu,manu_holdout$high_growth_factor)
cm5 <- cm_object5$table

# Confusion table on holdout services
holdout_pred_serv <-
  ifelse(serv_holdout$rf_p_serv_prediction < best_tresholds[["rf_p_serv"]], "low_growth", "high_growth") %>%
  factor(levels = c("low_growth", "high_growth"))
cm_object6 <- confusionMatrix(holdout_pred_serv,serv_holdout$high_growth_factor)
cm6 <- cm_object6$table


# observations in holdout
obs_holdout_manu <- nrow(manu_holdout)
obs_holdout_serv <- nrow(serv_holdout)

# add a version of the table where each cell is divided by the total number of observations
cm5_perc <- cm5/obs_holdout_manu
cm6_perc <- cm6/obs_holdout_serv

# add column and row totals
cm5_perc <- cbind(cm5_perc, rowSums(cm5_perc))
cm5_perc <- rbind(cm5_perc, colSums(cm5_perc))
cm6_perc <- cbind(cm6_perc, rowSums(cm6_perc))
cm6_perc <- rbind(cm6_perc, colSums(cm6_perc))


# add missing row and column names
cm5_perc <- as.data.frame(cm5_perc)
cm6_perc <- as.data.frame(cm6_perc)

colnames(cm5_perc) <- c("Actual Low Growth", "Actual High Growth", "Total")
rownames(cm5_perc) <- c("Predicted Low Growth", "Predicted High Growth", "Total")
colnames(cm6_perc) <- c("Actual Low Growth", "Actual High Growth", "Total")
rownames(cm6_perc) <- c("Predicted Low Growth", "Predicted High Growth", "Total")

# multiply each with 100 and add %
cm5_perc[] <- lapply(cm5_perc, function(x) sprintf("%.2f%%", x * 100))
cm6_perc[] <- lapply(cm6_perc, function(x) sprintf("%.2f%%", x * 100))

kable(x = cm5_perc, format = "latex", booktabs = TRUE,  digits = 3, row.names = TRUE,
      linesep = "")
kable(x = cm6_perc, format = "latex", booktabs = TRUE,  digits = 3, row.names = TRUE,
      linesep = "")


```

<!-- Task3.1: Use some methods to interpret your random forest probability model (Shapley, PDP) -->

<!-- RF VAR IMP (all 3) W/OUT LOSS adjust  -->

```{r}

# rf_models <- list(rf_model_p, rf_model_p_manu, rf_model_p_serv)
# # Create an empty list to store the plots
# rf_model_plots <- list()
# 
# # Loop over the random forest models
# for (i in seq_along(rf_models)) {
#   current_rf_model <- rf_models[[i]]
# 
# rf_model_var_imp <- importance(current_rf_model$finalModel)/1000
# 
# rf_model_var_imp_df <-
#   data.frame(varname = names(rf_model_var_imp),imp = rf_model_var_imp) %>%
#   #mutate(varname = gsub("f_neighbourhood_cleansed", "Borough:", varname) ) %>%
#   #mutate(varname = gsub("f_room_type", "Room type:", varname) ) %>%
#   arrange(desc(imp)) %>%
#   mutate(imp_percentage = imp/sum(imp))
# 
# 
# # Create plot VAR IMP ALL 
#   current_plot <- ggplot(rf_model_var_imp_df, aes(x = reorder(varname, imp), y = imp_percentage)) +
#     geom_point(color = color[1], size = 1) +
#     geom_segment(aes(x = varname, xend = varname, y = 0, yend = imp_percentage), color = color[1], size = 1) +
#     ylab("Importance (Percent)") +
#     xlab("Variable Name") +
#     coord_flip() +
#     scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
#     theme_minimal() +
#     theme(panel.grid.major.y = element_blank(),
#           axis.text.x = element_text(size = 6),
#           axis.text.y = element_text(size = 6),
#           axis.title.x = element_text(size = 6),
#           axis.title.y = element_text(size = 6))
#   
#   # Save the plot
#   rf_model_plots[[paste0("rf_model_plot_all_", i)]] <- current_plot
# 
# # Create plot VAR IMP TOP 10  
#   current_plot <- ggplot(rf_model_var_imp_df[1:10,], aes(x = reorder(varname, imp), y = imp_percentage)) +
#     geom_point(color = color[1], size = 1) +
#     geom_segment(aes(x = varname, xend = varname, y = 0, yend = imp_percentage), color = color[1], size = 1) +
#     ylab("Importance (Percent)") +
#     xlab("Variable Name") +
#     coord_flip() +
#     scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
#     theme_minimal() +
#     theme(panel.grid.major.y = element_blank(),
#           axis.text.x = element_text(size = 6),
#           axis.text.y = element_text(size = 6),
#           axis.title.x = element_text(size = 6),
#           axis.title.y = element_text(size = 6))
#   
#   # Save the plot
#   rf_model_plots[[paste0("rf_model_plot_10_", i)]] <- current_plot
# }
# 
# rf_model_plots$rf_model_plot_all_1
# rf_model_plots$rf_model_plot_10_1
# rf_model_plots$rf_model_plot_all_2
# rf_model_plots$rf_model_plot_10_2
# rf_model_plots$rf_model_plot_all_3
# rf_model_plots$rf_model_plot_10_3
```

```{r}
library(plotly)

# Create an empty list to store the plots
rf_model_plots <- list()

# Loop over the random forest models
for (i in seq_along(rf_models)) {
  current_rf_model <- rf_models[[i]]

  rf_model_var_imp <- importance(current_rf_model$finalModel) / 1000

  rf_model_var_imp_df <- data.frame(varname = names(rf_model_var_imp), imp = rf_model_var_imp) %>%
    arrange(desc(imp)) %>%
    mutate(imp_percentage = imp / sum(imp))

  # Create plot VAR IMP ALL 
  current_plot_all <- plot_ly(rf_model_var_imp_df, x = ~imp_percentage, y = ~reorder(varname, imp), type = 'bar', orientation = 'h') %>%
    layout(
      xaxis = list(title = "Importance", range = c(0, 0.07), tickvals = seq(0, 0.07, by = 0.01), tickformat = ".0%"),
      yaxis = list(title = "Variable Name"),
      showlegend = FALSE,
      barmode = 'stack',  # Use 'stack' mode to adjust bar width
      bargap = 0.2  # Adjust the bar width by changing bargap
    )

  # Save the plot
  rf_model_plots[[paste0("rf_model_plot_all_", i)]] <- current_plot_all

  # Create plot VAR IMP TOP 10  
  current_plot_10 <- plot_ly(rf_model_var_imp_df[1:10, ], x = ~imp_percentage, y = ~reorder(varname, imp), type = 'bar', orientation = 'h') %>%
    layout(
      xaxis = list(title = "Importance", range = c(0, 0.07), tickvals = seq(0, 0.07, by = 0.01), tickformat = ".0%"),
      yaxis = list(title = "Variable Name"),
      showlegend = FALSE,
      barmode = 'stack',  # Use 'stack' mode to adjust bar width
      bargap = 0.2  # Adjust the bar width by changing bargap
    )

  # Save the plot
  rf_model_plots[[paste0("rf_model_plot_10_", i)]] <- current_plot_10
}

# Print or view the plots
for (i in seq_along(rf_model_plots)) {
  print(rf_model_plots[[i]])
}


rf_model_plots$rf_model_plot_all_1

```



### Variable importance grouped

```{r}
### Variable importance top 10 
# use RF model since performed the best!
# first need a function to calculate grouped varimp
group.importance <- function(rf.obj, groups) {
  var.imp <- as.matrix(sapply(groups, function(g) {
    sum(importance(rf.obj)[g], na.rm = TRUE)
  }))
  colnames(var.imp) <- "MeanDecreaseGini"
  return(var.imp)
}
```

```{r,echo=FALSE, include=F, warning=F}
##############################
# 2) varimp plot grouped to (8)
##############################
# grouped variable importance - keep binaries created off factors together
# dmy <- dummyVars("~ ind + ind2 + ind2_cat + gender + origin + region_m + urban_m", 
#                  data = bisnode, fullRank = TRUE)

# # Loop over the random forest models
# for (i in seq_along(rf_models)) {
#   current_rf_model <- rf_models[[i]]
# 
# varnames <- current_rf_model$finalModel$xNames
# ind_varnames <- grep("ind",varnames, value = TRUE)
# gender_varnames <- grep("gender",varnames, value = TRUE)
# origin_varnames <- grep("origin",varnames, value = TRUE)
# region_m_varnames <- grep("region_m",varnames, value = TRUE)
# urban_m_varnames <- grep("urban_m",varnames, value = TRUE)
# 
# groups <- list(ind=ind_varnames,
#                gender = gender_varnames,
#                origin = origin_varnames,
#                region_m =region_m_varnames,
#                urban_m = urban_m_varnames)
# 
# rf_model_var_imp_grouped <- group.importance(current_rf_model$finalModel, groups)
# rf_model_var_imp_grouped_df <- data.frame(varname = rownames(rf_model_var_imp_grouped),
#                                             imp = rf_model_var_imp_grouped[,1])  %>%
#   mutate(imp_percentage = imp/sum(imp))
# 
# current_plot_group <- ggplot(rf_model_var_imp_grouped_df, aes(x = reorder(varname, imp), y = imp_percentage)) +
#   geom_point(color = color[1], size = 1) +
#   geom_segment(aes(x = varname, xend = varname, y = 0, yend = imp_percentage), color = color[1], size = 1) +
#   ylab("Importance (Percent)") +
#   xlab("Variable Name") +
#   coord_flip() +
#   scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
#   theme_minimal() +  # Change to theme_minimal or another theme of your choice
#   theme(panel.grid.major.y = element_blank(),  # Remove horizontal grid lines only
#         axis.text.x = element_text(size = 6),
#         axis.text.y = element_text(size = 6),
#         axis.title.x = element_text(size = 6),
#         axis.title.y = element_text(size = 6))
# 
#  # Save the plot
#   rf_model_plots[[paste0("rf_model_var_imp_grouped_plot", i)]] <- current_plot_group
# }
# rf_model_plots$rf_model_var_imp_grouped_plot1
# rf_model_plots$rf_model_var_imp_grouped_plot2
# rf_model_plots$rf_model_var_imp_grouped_plot3
```


```{r,echo=FALSE, include=F, warning=F}
######################################################

library(plotly)

# Create an empty list to store the plots
rf_model_plots_grouped <- list()

# Loop over the random forest models
for (i in seq_along(rf_models)) {
  current_rf_model <- rf_models[[i]]

  varnames <- current_rf_model$finalModel$xNames
  ind_varnames <- grep("ind", varnames, value = TRUE)
  gender_varnames <- grep("gender", varnames, value = TRUE)
  origin_varnames <- grep("origin", varnames, value = TRUE)
  region_m_varnames <- grep("region_m", varnames, value = TRUE)
  urban_m_varnames <- grep("urban_m", varnames, value = TRUE)

  groups <- list(ind = ind_varnames,
                 gender = gender_varnames,
                 origin = origin_varnames,
                 region_m = region_m_varnames,
                 urban_m = urban_m_varnames)

  rf_model_var_imp_grouped <- group.importance(current_rf_model$finalModel, groups)
  rf_model_var_imp_grouped_df <- data.frame(
    varname = rownames(rf_model_var_imp_grouped),
    imp = rf_model_var_imp_grouped[, 1]
  ) %>%
    mutate(imp_percentage = imp / sum(imp))

  current_plot_group <- plot_ly(
    rf_model_var_imp_grouped_df,
    x = ~imp_percentage,
    y = ~reorder(varname, imp),
    type = 'bar',
    orientation = 'h',
    marker = list( width = 0.5)
  ) %>%
    layout(
      xaxis = list(title = "Importance", tickformat = ".0%", range = c(0, max(rf_model_var_imp_grouped_df$imp_percentage) + 0.01)),
      yaxis = list(title = "Variable Name"),
      showlegend = FALSE
    )

  # Save the plot
  rf_model_plots_grouped[[paste0("rf_model_var_imp_grouped_plot", i)]] <- current_plot_group
}

# Print or view the plots
for (i in seq_along(rf_model_plots_grouped)) {
  print(rf_model_plots_grouped[[i]])
}
rf_model_plots_grouped$rf_model_var_imp_grouped_plot1
```

<!-- Shapley (all 3) AGAIN W/OUT LOSS adjust  -->

```{r,echo=FALSE, include=FALSE, warning=F}
## SHAP VALUES ##
# rfvars
# ### correct facors chosen?? 
# 
# # define one-hot encoding function
# # dmy <- dummyVars("~ ind + ind2 + ind2_cat + gender + origin + region_m + urban_m", 
# #                  data = bisnode_holdout, fullRank = TRUE)
# 
# # #perform one-hot encoding on data frame
# 
#  data_holdout_ohe <- data.frame(predict(dmy, newdata=bisnode_holdout))
# # 
# # # replace "." character to " " to match model object names
# names(data_holdout_ohe) <- gsub(x = names(data_holdout_ohe),
#                                 pattern = "\\.",
#                                 replacement = " ")
# # # unify model for treeshap
# ## now porblem appa. with RF? 
# 
# rf_model_unified <- ranger.unify(rf_model_p$finalModel, bisnode_holdout)
# 
# 
# 
# rf_model_p$finalModel$nu
# 
# ranger_model <- rf_model_p_manu$finalModel
# 
# tree_info <- ranger_model$unique.tree.info
# 
# 
# 
# # # when: Error in set_reference_dataset(ret, as.data.frame(data)) : 
# # # Dataset does not contain all features occurring in the model.
# # 
# # #model_variable_names <- rf_model$coefnames
# # #new_data_variable_names <- colnames(data_holdout_ohe)
# # 
# # #missing_variables <- setdiff(rf_model$coefnames, new_data_variable_names)
# # #if (length(missing_variables) > 0) {
# #  # stop(paste("Error: Missing variables in new data:", toString(missing_variables)))
# # #}
# # # if Error message (add variables from Error here manually)
# # # Identify the indices of the columns you want to change
# # indices_to_change <- which(colnames(data_holdout_ohe) %in% c("neighbourhood_cleansedBrnshj Husum", "neighbourhood_cleansedVesterbro Kongens Enghave"))
# # 
# # # Create a vector of new column names for the selected columns
# # new_names <- c("neighbourhood_cleansedBrnshj-Husum", "neighbourhood_cleansedVesterbro-Kongens Enghave")
# # 
# # # Change the column names only for the selected columns
# # names(data_holdout_ohe)[indices_to_change] <- new_names
# # 
# # ## go back to unify model for treeshap
# # 
# # #rf_model_unified <- ranger.unify(rf_model$finalModel, data_holdout_ohe)
# # 
# treeshap_res <- treeshap(rf_model_p, data_holdout_ohe[1:500, ]) # delete # for calculation but excluded here for Rmd knitting 
# # 
# # #treeshap_res <- plot_contribution(treeshap_res, obs = 12)
# # 
# # #treeshap_featureIMP <- plot_feature_importance(treeshap_res, max_vars = 10)
# # 
# # #treeshap_inter <- treeshap(rf_model_unified, data_holdout_ohe[1:100, ], interactions = T)
# # #summary(treeshap_res)
```

```{r,echo=FALSE, include=FALSE, warning=F, eval=FALSE}
#########################################################################################
# Partial Dependence Plots -------------------------------------------------------
#########################################################################################
varnames

# below code does not work!!! T: Attention included eval = false s.t I  could knit, delete this once the PDP code works!!!
pdp_n_acc <- pdp::partial(rf_model_p, pred.var = "ceo_count", pred.grid = distinct_(bisnode_holdout, "ceo_count"), train = bisnode_work)



pdp_n_acc_plot <- pdp_n_acc %>%
  autoplot( ) +
  geom_point(color=color[1], size=2) +
  geom_line(color=color[1], size=1) +
  ylab("Growth") +
  xlab("ceo_count") +
  scale_x_continuous(limit=c(1,7), breaks=seq(1,7,1))+
theme_bg()
pdp_n_acc_plot


### factors?? 

rfvars
pdp_n_roomtype <- pdp::partial(rf_model_p, pred.var = "origin", pred.grid = distinct_(bisnode_holdout, "origin"), train = bisnode_work)
pdp_n_roomtype_plot <- pdp_n_roomtype %>%
  autoplot( ) +
  geom_point(color=color[1], size=2) +
  ylab("Predicted price") +
  xlab("Room type") +
  #scale_y_continuous(limits=c(60,120), breaks=seq(60,120, by=10)) +
  theme_bg()
pdp_n_roomtype_plot
```

<!-- Task 3.2: Show expected loss based on different thresholds. -->
<!-- Kick out this chunk if the one below works for shiny-->
```{r}
#######
# does make some custom plots (but Gabor's are nicer)
# all_thresholds_cv <- list()
# all_losses_cv <- list()
# 
# for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
#   cv_fold <- 
#     rf_model_p$pred %>%
#     filter(mtry == best_mtry,
#            min.node.size == best_min_node_size,
#            Resample == fold)
# 
#   roc_obj <- roc(cv_fold$obs, cv_fold$high_growth)
# 
#   # Evaluate at several thresholds
#   thresholds <- seq(0, 1, by = 0.01)
#   losses <- numeric(length(thresholds))
# 
#   for (i in seq_along(thresholds)) {
#     threshold <- thresholds[i]
#     coords_obj <- coords(roc_obj, x=threshold, input="threshold", ret="all", transpose=FALSE)
#     
#     # Calculate expected loss
#     losses[i] <- (coords_obj$fp*FP + coords_obj$fn*FN)/length(cv_fold$high_growth)
#   }
# 
#   all_thresholds_cv[[fold]] <- thresholds
#   all_losses_cv[[fold]] <- losses
# }
# 
# # Now you can plot the losses for each fold
# for (fold in names(all_thresholds_cv)) {
#   plot(all_thresholds_cv[[fold]], all_losses_cv[[fold]], type="l", 
#        xlab="Threshold", ylab="Expected Loss", main=paste("Expected Loss for", fold))
#   lines(all_thresholds_cv[[fold]], all_losses_cv[[fold]], col="blue")
# }
# 

```


```{r}
createInteractLossPlot <- function(r, best_coords, file_name, myheight_small = 5.625, mywidth_small = 7.5) {
  t <- best_coords$threshold[1]
  sp <- best_coords$specificity[1]
  se <- best_coords$sensitivity[1]
  n <- rowSums(best_coords[c("tn", "tp", "fn", "fp")])[1]

  all_coords <- coords(r, x="all", ret="all", transpose = FALSE)
  all_coords <- all_coords %>%
    mutate(loss = (fp*FP + fn*FN)/n)
  l <- all_coords[all_coords$threshold == t, "loss"]

  loss_plot <- ggplot(data = all_coords, aes(x = threshold, y = loss)) +
    geom_line(color=color[1], size=0.7) +
    scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.1)) +
    geom_vline(xintercept = t, color = color[2]) +
    theme_bg()

  # Convert to plotly for interactivity
  interactive_plot <- ggplotly(loss_plot) %>%
    layout(hovermode = 'x') %>%
     layout(annotations = list(
        list(
            x = t,
            y = min(all_coords$loss),
            text = paste0("best threshold: ", round(t,2)),
            showarrow = TRUE,
            arrowhead = 1,
            ax = 20,  # adjust for better positioning
            ay = -30, # adjust for better positioning
            xanchor = 'center',
            yanchor = 'bottom',
            font = list(
                family = "Arial",
                size = 12,
                color = color[2]
            )
        )
    ))
  # Save or display the interactive plot
  # ggsave(plot = interactive_plot, paste0(file_name,".html"), width=mywidth_small, height=myheight_small)
  # or
  interactive_plot
}
```


```{r}
# re-run losses for RF s.t roc_object is correctly stored

## bisnode

# Now use loss function and search for best thresholds and expected loss over folds -----
best_tresholds_cv <- list()
expected_loss_cv <- list()

for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
  cv_fold <-
    rf_model_p$pred %>%
    filter(mtry == best_mtry,
           min.node.size == best_min_node_size,
           Resample == fold)

  roc_obj <- roc(cv_fold$obs, cv_fold$high_growth)
  best_treshold <- coords(roc_obj, "best", ret="all", transpose = FALSE,
                          best.method="youden", best.weights=c(cost, prevalence))
  best_tresholds_cv[[fold]] <- best_treshold$threshold
  expected_loss_cv[[fold]] <- (best_treshold$fp*FP + best_treshold$fn*FN)/length(cv_fold$high_growth)
}

rf_model_p_InteractLossPlot <- createInteractLossPlot(roc_obj, best_treshold, "rf_p_interact_loss_plot")

```

```{r}
# re-run losses for RF s.t roc_object is correctly stored

## manu

# Now use loss function and search for best thresholds and expected loss over folds -----
best_tresholds_cv <- list()
expected_loss_cv <- list()

for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
  cv_fold <-
    rf_model_p_manu$pred %>%
    filter(mtry == best_mtry,
           min.node.size == best_min_node_size,
           Resample == fold)

  roc_obj <- roc(cv_fold$obs, cv_fold$high_growth)
  best_treshold <- coords(roc_obj, "best", ret="all", transpose = FALSE,
                          best.method="youden", best.weights=c(cost, prevalence))
  best_tresholds_cv[[fold]] <- best_treshold$threshold
  expected_loss_cv[[fold]] <- (best_treshold$fp*FP + best_treshold$fn*FN)/length(cv_fold$high_growth)
}

rf_model_p_manu_InteractLossPlot <- createInteractLossPlot(roc_obj, best_treshold, "rf_p_manu_interact_loss_plot")
#rf_model_p_manu_InteractLossPlot
```

```{r}
# re-run losses for RF s.t roc_object is correctly stored

## services

# Now use loss function and search for best thresholds and expected loss over folds -----
best_tresholds_cv <- list()
expected_loss_cv <- list()

for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
  cv_fold <-
    rf_model_p_serv$pred %>%
    filter(mtry == best_mtry,
           min.node.size == best_min_node_size,
           Resample == fold)

  roc_obj <- roc(cv_fold$obs, cv_fold$high_growth)
  best_treshold <- coords(roc_obj, "best", ret="all", transpose = FALSE,
                          best.method="youden", best.weights=c(cost, prevalence))
  best_tresholds_cv[[fold]] <- best_treshold$threshold
  expected_loss_cv[[fold]] <- (best_treshold$fp*FP + best_treshold$fn*FN)/length(cv_fold$high_growth)
}

rf_model_p_serv_InteractLossPlot <- createInteractLossPlot(roc_obj, best_treshold, "rf_p_serv_interact_loss_plot")
#rf_model_p_serv_InteractLossPlot
```
# Overall Summary

We estimated three models to predict high growth firms (logit, logit LASSO, random forest). Random forest turned out to be the best model, both, when evaluated based on RMSE or AUC as well as expected loss.

Our definition of high growth is based on average annual sales growth over two years ahead above 30%. In our loss function we assigned 50% higher costs to false positives, reflecting our desire to avoid bad investments. This decision lead to a high specificity of our classification but at the same time to a low sensitivity. We prefer this trade-off since we do not need to identify all high growth firms but rather just find some of them with enough confidence to make an investment. 

## Section on variable importance/PDP/Shapley here (into dashboard)
What is more, we analyzed the influence of the variables entering our model. We find that XXXX.

In a next step we applied our model to the two segments of manufacturing and services. The model performs better in the services sector leading to lower false positives and lower false negatives.

XXXX

<!-- Save data environment for dashboard  -->

```{r}
save.image(file = "A3.RData") # specify location 
# delete all data not needed !!!! to make shiny faster!!! 
```

<!-- References 
ChatGPT, Shiny Package: selectInput Function, December 13, 2023.
Retrieved from: https://chat.openai.com/share/7029becb-1062-49e2-9755-eb1baa46ea26

Békés,G., Kézdi,G.(2021).R, Python and Stata code for Data Analysis for Business, Economics, and Policy, ch17-predicting-firm-exit  , GitHub repository, https://github.com/gabors-data-analysis/da_case_studies/tree/master/ch17-predicting-firm-exit

Békés, G., & Kézdi, G. (2021). Data analysis for business, economics, and policy. Cambridge University Press, chapter 17.!--> 
