---
title: "Assignment 3 - Finding fast growing firms"
subtitle: "Course: ECBS6067 - Prediction with Machine Learning for Economists"
author: "Anja Hahn, Teresa Huebel & Anne Valder"
date: "2023-12-14"
output:
  pdf_document: default
  html_document:
  df_print: paged
---

```{r, include=FALSE}
# Clear memory
rm(list=ls())

# set global chunk options
knitr::opts_chunk$set(include = FALSE, fig.align = 'center', cache = TRUE,
                      warning = FALSE, message = FALSE, echo = FALSE)

options(scipen = 999)

```

```{r setup, include=FALSE}
# Set options for markdown
knitr::opts_knit$set(root.dir = 'C:/Users/avalder/OneDrive - WU Wien/Documents/Study/WS_23_24/Pred_MLE_Econ/da_case_studies')

# store different directories here:
# C:/Users/thuebel/OneDrive - WU Wien/Docs/06 Courses and Study/02 Prediction with ML for Economists/da_case_studies
# C:/Users/avalder/OneDrive - WU Wien/Documents/Study/WS_23_24/Pred_MLE_Econ/da_case_studies
# C:/Users/AnjaHahn/OneDrive - DataScience Service GmbH/WU/Courses/CEU Prediction with Machine Learning for Economists/da_case_studies

```

<!-- Set directory, load functions and theme  --> 
```{r, include=FALSE}
#getwd()
source("set-data-directory.R")
source("ch00-tech-prep/theme_bg.R")
source("ch00-tech-prep/da_helper_functions.R")


data_in <- paste(data_dir,"bisnode-firms","clean/", sep = "/")
#use_case_dir <- "ch17-predicting-firm-exit/"
```

```{r,include=FALSE, warning=FALSE}
#load libraries
library(tidyverse)
library(caret)
library(ranger)
library(Hmisc)
library(knitr)
library(modelsummary)
library(treeshap)
library(summarytools)
# add
```

<!-- Load data  --> 
```{r,include=FALSE}
bisnode <- read_csv(paste(data_in,"cs_bisnode_panel.csv", sep = "/")) # 287829 obs. of 48 variables 
```

<!-- Data summary  --> 
```{r, include=FALSE}
# count missing values
colSums(is.na(bisnode))
colSums(is.na(bisnode))/nrow(bisnode)*100

# look at data
bisnode %>% glimpse()

# look at character variables
bisnode %>%
  group_by(gender) %>%
  summarise(n = n(), mean = mean(sales))

# overall summary statistics
 #descr(bisnode)

```

<!-- Data preparation  --> 

```{r}

# re-code one character variable
bisnode <- bisnode %>%
  mutate(urban_m = case_when(
      urban_m == 1 ~ "capital_city",
      urban_m == 2 ~ "other_big_city",
      urban_m == 3 ~ "other"))

# convert character variables to one-hot-encoding
bisnode <- bisnode %>% 
  mutate_if(is.character, as.factor)
dmy <- dummyVars("~ gender + origin + region_m + urban_m", data = bisnode, fullRank = TRUE)
# @Teresa - warum hier fullRank = TRUE? ich hätte gefühlsmäßig FALSE genommen, hab aber jetzt auch nicht wirklich viel darüber gefunden

new_dat <- data.frame(predict(dmy, newdata = bisnode))
# @Anne: From your experience with A2, will the column names with "." make trouble now that we one-hot-encode in the beginning? Kann sein sollte aber kein Problem sein, können wir im Zweifel dann vor Shapeley umformatieren :)

# add new variables to data
bisnode <- cbind(bisnode, new_dat)

```

<!-- Sample design  --> 

```{r, include=FALSE}
####################################
# Sample design
####################################
# collect "weird stuff" here:
# Company with ID 12212152320 had a massive explosion from 2012 to 2013 (0 to 63 employees etc) - how to treat?
## did they exit before? Maybe we have to add a variable that indicate newly established firms?

# add all missing year and company combinations
bisnode <- bisnode %>%
  complete(year, comp_id)

# drop variables with many NAs
# Question from Anne: do we need to drop net_dom_sales, net_exp_sales or can we somehow impute would also make a good growth indicator export/ domestic sales or? also wages
bisnode <- bisnode %>%        
  select(-c(COGS, finished_prod, net_dom_sales, net_exp_sales, wages, D))
# potentially also drop unused years (e.g. 2016), yes I would drop it I guess he had good reasons to do it.

# find the years with the least missing sales values
bisnode %>%
  group_by(year) %>%
  summarise(missing = sum(is.na(sales))) %>%
  arrange(missing)
# biggest sample would be 2013-2014
# NAs of all variables per year 
bisnode %>%
  group_by(year) %>%
  summarise(across(everything(), ~ mean(is.na(.)) * 100, .names = "na_share_{.col}")) %>%
  ungroup()

# generate status_alive, we only want to analyse active firms
bisnode  <- bisnode %>%
  mutate(status_alive = sales > 0 & !is.na(sales) %>%
           as.numeric(.))

# generate different variations to display sales
# @Teresa - maybe have that under label engineering?
# Question Anne:   mutate(sales = ifelse(sales < 0, 1, sales), warum macht er aus sales einfach einen dummy?
bisnode <- bisnode %>%
  filter(status_alive == TRUE) %>% # only look at firms that have some sales
  mutate(ln_sales = log(sales), # if we want to include firms not_alive need to specially treat 0
         sales_mil=sales/1000000,
         sales_mil_log = ifelse(sales > 0, log(sales_mil), 0))
# this already windsorizes sales

# look at cross section
bisnode <- bisnode %>%
  filter(status_alive == TRUE) %>% # only look at firms that have some sales
  # look at firms below 10m euro revenues and above 1000 euros
  filter(!(sales_mil > 10)) %>%
  filter(!(sales_mil < 0.001))

# generate different variations to display labor_avg
# @Teresa - maybe have that under label engineering?(together with data visualization below?)
bisnode <- bisnode %>%
  mutate(ln_labor_avg = ifelse(labor_avg > 0, log(labor_avg), 0))

# Anne: I agree, I think I would put every modification in terms of sales/ labor_avg (wage) into section label engineering
## (but only a formal thing not so important)


## I think we should add firm age, also relevant in regard of command line 117. 
# Something like this:
#data <- data %>%
 # mutate(age = (year - founded_year) %>%
  #         ifelse(. < 0, 0, .),
   #      new = as.numeric(age <= 1)
```


<!-- Data visualization  --> 

```{r, include=FALSE}
# visualize sales
plot_sales <-  ggplot(bisnode, aes(x = sales)) +
  geom_histogram(bins = 100, fill = color[1], color = color.outline, alpha = 0.8) +
  scale_x_log10() +
  labs(x = "Sales (log)", y = "Frequency")+
  theme_bg() #Anne: I added his theme I think he likes that :D 
plot_sales

# visualize labor_avg
plot_labor_avg <- bisnode %>% filter(labor_avg > 0) %>%
  ggplot(aes(x = labor_avg)) +
  geom_histogram(bins = 100, fill = color[1], color = color.outline, alpha = 0.8) +
  labs(x = "Average Number of Employees", y = "Frequency") +
  xlim(0, 5) +
    theme_bg() #Anne: I added his theme I think he likes that :D 
plot_labor_avg
# in codebook: N/12 --- (annual average / 12, it's not ideal, sorry) 
# what does this mean?

```



<!-- Label engineering  --> 

```{r, include=FALSE}
####################################
# Label engineering
####################################
###################################
# Creation of different labels: sales
###################################

# YoY relative sales growth
bisnode <- bisnode %>%
  group_by(comp_id) %>%
  arrange(year) %>%
  mutate(sales_growth = (sales/lag(sales) -1)) %>%
  ungroup()

# YoY sales growth as logdiff
bisnode <- bisnode %>%
  group_by(comp_id) %>%
  arrange(year) %>%
  mutate(d1_sales_mil_log = sales_mil_log - Lag(sales_mil_log) ) %>%
  ungroup()

###################################
# Visualization sales growth

# make histogram that shows both sales growth and d1_sales_mil_log
plot_sales_growth_both <- ggplot(bisnode, aes(x = sales_growth)) +
  geom_histogram(aes(fill = "Percentage Change"), bins = 100, color = color.outline, alpha = 0.5) +
  geom_histogram(aes(x = d1_sales_mil_log, fill = "Log-Differences"), bins = 100, 
                 color = color.outline, alpha = 0.5) +
  scale_x_log10() +
  labs(x = "Sales growth (log)", y = "Frequency") +
  scale_fill_manual(values = c("Percentage Change" = color[1], "Log-Differences" = color[2]), 
                    name = "Growth Measures") +
  theme_bg()#Anne: I added his theme I think he likes that :D 

plot_sales_growth_both
# It makes a difference whether relative growth is measured in log(diff) or percentage change
# since logdiff is an inaccurate approximation for high changes this is especially relevant for high growth firms
# Anne: Percentage change gives us a more normal distribution though or?

###################################
# Creation of different labels: employment
###################################
# YoY relative employee growth
bisnode <- bisnode %>%
  group_by(comp_id) %>%
  arrange(year) %>%
  mutate(labor_growth = (labor_avg/lag(labor_avg) - 1)) %>%
  ungroup()

# YoY employee growth as logdiff
bisnode <- bisnode %>%
  group_by(comp_id) %>%
  arrange(year) %>%
  mutate(d1_labor_avg_log = ln_labor_avg - Lag(ln_labor_avg) ) %>%
  ungroup()

# birch index (weighted index of absolute and relative employment growth)
bisnode <- bisnode %>%
  group_by(comp_id) %>%
  arrange(year) %>%
  mutate(birch_ind = ((labor_avg - lag(labor_avg)) * (labor_avg/lag(labor_avg) - 1)) ) %>%
  ungroup()

###################################
# Visualization employment growth

#make histogram that shows both employee growth and d1_labor_avg_log
plot_labor_growth_both <- ggplot(bisnode, aes(x = labor_growth)) +
  geom_histogram(aes(fill = "Percentage Change"), bins = 100, color = color.outline, alpha = 0.5) +
  geom_histogram(aes(x = d1_labor_avg_log, fill = "Log-Differences"), bins = 100, 
                 color = color.outline, alpha = 0.5) +
  labs(x = "Employee growth (log)", y = "Frequency") +
  scale_fill_manual(values = c("Percentage Change" = color[1], "Log-Differences" = color[2]), 
                    name = "Growth Measures") +
  scale_x_log10() #+
 # theme_bg()
plot_labor_growth_both

####################################
# notes on growth
####################################
# different types of growth
# yoy relative growth in sales
# average yoy relative growth in sales over 2 years
# yoy relative growth in employees
# average yoy relative growth in employees over 2 years

# cutoff:
# classify as "fast" if they meet a combination of the above?
# OECD definition: 20% average growth in sales or employees over 3 years
# do the same but only with 2 years? Anne: sounds good and justified to me!

# in literature it has been suggested to use fastest growing percintile 8e.g. to 5% of firms)
# see: https://www.diva-portal.org/smash/get/diva2:605658/FULLTEXT01.pdf
# rather than hard cutoff --> but not meaningful for us if we want to compare growth in different industries
# a lot of firms with 0-1 employees: might need a lower absolute threshold for growth such that tiny firms that
# add one extra employee are not classified as fast growing?
####### Question:  0-1 new employees or in general? If there are any with 0 employees we should get rid of them anyways or?
```



<!-- Feature engineering COMMENTS  --> 

```{r}
# I would also add a variable 'new' (see above and line 117). But yes maybe age and new both to sample design
# industry codes look good!


# why did we not add these?  
#gender_m = factor(gender, levels = c("female", "male", "mix")),
#m_region_loc = factor(region_m, levels = c("Central", "East", "West")))

# function help check variables: summary(as.factor(bisnode$ceo_age)) # its also a bit weird they are not orderd should be the case for a numerical variable; maybe some error in calculation? above 90 also seems unlikely or?

# # Q: why are tangible assets not included in Gabors code?
## Just a guess but I think tangible assets (production sides, machines etc) depending on firm category not that relevant for firm? I think he wanted to put more emphasize on the financial side/ worth. 


# ceo_young < 25 why did we chose another threshold? 
# do has he did for imputation? data <- data %>%
 # mutate(ceo_age = ifelse(ceo_age < 25, 25, ceo_age) %>%
      #     ifelse(. > 75, 75, .) %>%
       #    ifelse(is.na(.), mean(., na.rm = TRUE), .),
       #  ceo_young = as.numeric(ceo_age < 40))

# # sales?? line 503 maybe do grpah and basic lm to see which terms (squares etc) to include or? 
```


<!-- Feature engineering  --> 

```{r, include=FALSE}
###################################
# new variables

# group some industry category codes (2-digit NACE)
# use ChatGPT to suggest similar groups (maximum of 5 groups)
bisnode <- bisnode %>%
  mutate(ind2_cat = case_when(
    ind2 < 10 ~ "primary_extractive",
    ind2 >= 10 & ind2 < 40 ~ "manufact_utilities",
    ind2 > 40 & ind2 < 84 ~ "services",
    ind2 >= 84 & ind2 < 90 ~ "public_health_edu",
    ind2 >= 90 ~ "arts"
  ))

# firm characteristics
bisnode <- bisnode %>%
  mutate(age = (year-founded_year) %>% # maybe remove again if computed earlier
           ifelse(. < 0, 0, .),
         age2 = age^2,
         foreign_management = as.numeric(foreign >= 0.5),
         multiple_ceo = as.numeric(ceo_count > 1),
         ceo_age = (year-round(birth_year))) # avoid digits for years

###################################
# plausibility checks of relevant numeric variables
for (var in c("age", "ceo_age", "ceo_count", "inoffice_days",
             "curr_assets", "curr_liab", "extra_exp", "extra_inc",
             "extra_profit_loss", "fixed_assets", "inc_bef_tax",
             "intang_assets", "inventories", "liq_assets", "material_exp",
             "personnel_exp", "profit_loss_year", "share_eq", "subscribed_cap",
             "tang_assets")){
  print(paste(paste0(var, 
                     ": min:", 
                     min(bisnode[, var], na.rm = TRUE), 
                     "; max:"),
              max(bisnode[, var], na.rm = TRUE)))
}
rm(var)

###################################
# problematic data
# age CEO cannot be negative, also some too young
bisnode <- bisnode %>%
  mutate(ceo_age = ifelse(ceo_age < 18, NA, ceo_age)) # overwrite implausible ones with NA for now

# there cannot be negative financial variables
zero <- c("curr_liab", "curr_assets", "extra_exp", "extra_inc", "fixed_assets",
          "intang_assets", "inventories", "liq_assets", "material_exp",
          "personnel_exp", "subscribed_cap", "tang_assets") #share_eq?

# flag negative ones
for (var in zero){
  aux <- paste0(var, "_flag_error")
  bisnode[, aux] <- as.numeric(bisnode[, var] < 0)
}

# flag any negative assets (extra variable)
bisnode <- bisnode %>%
  mutate(flag_asset_problem = ifelse(intang_assets < 0 | curr_assets < 0 | fixed_assets < 0, 1, 0))

# set negative ones to zeros
bisnode <- bisnode %>%
  mutate_at(vars(zero), funs(ifelse(. < 0, 0, .)))


###################################
# NA analysis and imputation
colSums(is.na(bisnode))/nrow(bisnode)*100

# drop missing important variables
# drop about 20%
bisnode <- bisnode %>%
  filter(!is.na(liq_assets), # representative of missing assets data
         !is.na(foreign), # representative of missing CEO data
         !is.na(ind), # representative of industry data
         !is.na(region_m)) # geographical info

# impute important ones
# ceo age
bisnode <- bisnode %>%
  mutate(flag_missing_ceo_age = as.numeric(is.na(ceo_age)),
         ceo_age = round(ifelse(is.na(ceo_age), mean(ceo_age, na.rm = TRUE), ceo_age)))

# number of employees
# not sure if needed bc reflected in response?
bisnode <- bisnode %>%
  mutate(flag_miss_labor_avg = as.numeric(is.na(labor_avg)),
         labor_avg = ifelse(is.na(labor_avg), mean(labor_avg, na.rm = TRUE), labor_avg))

# sales?
# not sure if needed bc reflected in response?

# still existing NAs
for (var in names(bisnode)){
  
  if(any(is.na(bisnode[, var]))){
    print(paste0(var, ":", sum(is.na(bisnode[, var]))/nrow(bisnode)))
  }
}



###################################
# new variables and 
# variable transformation

# impute age CEO and calculate new variable
bisnode <- bisnode %>%
  mutate(ceo_young = as.numeric(ceo_age < 40 & !is.na(ceo_age)),
         ceo_old = as.numeric(ceo_age > 75 & !is.na(ceo_age)))

# generate total assets
bisnode <- bisnode %>%
  mutate(total_assets = intang_assets + curr_assets + fixed_assets) # Q: why are tangible assets not included in Gabors code?

# compute relative variables (sales as reference)
bisnode <- bisnode %>%
  mutate_at(vars("extra_exp", "extra_inc", "extra_profit_loss", 
                 "inc_bef_tax", "inventories", "material_exp",
                 "profit_loss_year", "personnel_exp"),
            funs("rel" = ./sales))

# compute relative variables (total assets as reference)
bisnode <- bisnode %>%
  mutate_at(vars("intang_assets", "curr_liab", "fixed_assets", 
                 "liq_assets", "curr_assets", "share_eq", 
                 "subscribed_cap", "tang_assets"),
            funs("rel" = ifelse(total_assets == 0, 0, ./total_assets)))


###################################
# creating flags and winsorizing tails

# overwrite selected variables with relative ones
zero <- paste0(zero, "_rel")

# flag very high observations and set them to 1
bisnode <- bisnode %>%
  mutate_at(vars(zero), funs("flag_high"= as.numeric(. > 1))) %>%
  mutate_at(vars(zero), funs(ifelse(. > 1, 1, .)))

# for vars that could be any (also negative), but are mostly between -1 and 1
any <-  c("extra_profit_loss_rel", "inc_bef_tax_rel", "profit_loss_year_rel", "share_eq_rel")

# add flags and set tails to -1/1 and add quadratics
bisnode <- bisnode %>%
  mutate_at(vars(any), funs("flag_low" = as.numeric(. < -1))) %>%
  mutate_at(vars(any), funs(ifelse(. < -1, -1, .))) %>%
  mutate_at(vars(any), funs("flag_high" = as.numeric(. > 1))) %>%
  mutate_at(vars(any), funs(ifelse(. > 1, 1, .))) %>%
  mutate_at(vars(any), funs("flag_zero" = as.numeric(. == 0))) %>%
  mutate_at(vars(any), funs("quad" = .^2))

# dropping flags with no variation
variances <- bisnode %>%
  select(contains("flag")) %>%
  apply(2, var, na.rm = TRUE) == 0
bisnode <- bisnode %>%
  select(-one_of(names(variances)[variances]))


# sales??
data <- data %>%
  mutate(flag_low_d1_sales_mil_log = ifelse(d1_sales_mil_log < -1.5, 1, 0),
         flag_high_d1_sales_mil_log = ifelse(d1_sales_mil_log > 1.5, 1, 0),
         d1_sales_mil_log_mod = ifelse(d1_sales_mil_log < -1.5, -1.5,
                                       ifelse(d1_sales_mil_log > 1.5, 1.5, d1_sales_mil_log)),
         d1_sales_mil_log_mod_sq = d1_sales_mil_log_mod^2
         )




# missing values
# interactions (irrelevant ML?) yes
# functional form (irrelevant ML?) yes
# select and store variables for each model (paste formulas)

# one-hot encode
dmy <- dummyVars("~ ind2_cat", data = bisnode, fullRank = FALSE) # or true?
new_dat <- data.frame(predict(dmy, newdata = bisnode))
# add new variables to data
bisnode <- cbind(bisnode, new_dat)


# discard variables not needed anymore
bisnode <- bisnode %>%
  select(-c("gender", "origin", "region_m"))

# create factors
data <- data %>%
  mutate(urban_m = factor(urban_m, levels = c(1,2,3)),
         ind2_cat = factor(ind2_cat, levels = sort(unique(data$ind2_cat))))

data <- data %>%
  mutate(default_f = factor(default, levels = c(0,1)) %>%
           recode(., `0` = 'no_default', `1` = "default"))

```

<!-- Preparation for prediction & CV  --> 
```{r,include=FALSE}

set.seed(123456)

work_indices <- as.integer(createDataPartition(bisnode$default, p = 0.8, list = FALSE))
bisnode_work <- bisnode[train_indices, ]
bisnode_holdout <- bisnode[-train_indices, ]

dim(bisnode_work)
dim(bisnode_holdout)

# separation into train and test automatically via cross-validation using caret package

n_folds = 5
train_control <- trainControl(method = "cv",
                              number = n_folds,
                              classProbs = TRUE, # computing probabilities during training
                              summaryFunction = twoClassSummaryExtended, # from da_helper_functions.R
                              savePredictions = TRUE # save the predictions for each fold
                              )
# train_control$verboseIter <- TRUE # add that for RF

```


<!-- Task1.1: Model 1 - Logit  --> 
<!-- Task1.1: Model 2 - Random forest  --> 
<!-- Task1.1: Model 3 - Logit LASSO?? / Classification Tree?  -->
<!-- Task1.1: Evaluation  -->
```{r}
# No loss function
# RMSE (AUC also?based on threshold that corresponds to prevalence of pos/neg in dataset)
```


<!-- Task1.2: Loss function design -->
<!-- Task1.2: For each of the three models: predict probabilities, look for the optimal classification threshold, calculate expected loss with your loss function  -->
<!-- Task1.2: Pick model with smallest expected loss -->
```{r}

```

<!-- Task1.3: Show a confusion table (on a selected fold or holdout set) -->
<!-- Task1.3: Discuss results, evaluate how useful your model may be -->
```{r}

```

<!-- Task2.1: 2 Samples (service & manufacturing)  --> 

```{r}

```
<!-- Task2.2: Define single loss function (Same loss function as before?) but use for samples separately (pick one prediction model) --> 

```{r}

```

<!-- Task2.3: Compare the model performance across two samples -->

```{r}

```

<!-- Task3.1: Use some methods to interpret your random forest probability model (Shapley, PDP) --> 
<!-- Task3.2: Create a shiny (flexdashboard) app for the project where you can show (1) how key variables influence the prediction (!Shapley) and (2) show expected loss based on different thresholds. -->