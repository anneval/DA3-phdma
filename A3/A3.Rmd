---
title: "Assignment 3 - Finding fast growing firms"
subtitle: "Course: ECBS6067 - Prediction with Machine Learning for Economists"
author: "Anja Hahn, Teresa Huebel & Anne Valder"
date: "2023-12-14"
output:
  pdf_document: default
  html_document:
  df_print: paged
---

```{r, include=FALSE}
# Clear memory
rm(list=ls())

# set global chunk options
knitr::opts_chunk$set(include = FALSE, fig.align = 'center', cache = TRUE,
                      warning = FALSE, message = FALSE, echo = FALSE)

options(scipen = 999)

```

```{r setup, include=FALSE}
# Set options for markdown
knitr::opts_knit$set(root.dir = 'C:/Users/AnjaHahn/OneDrive - DataScience Service GmbH/WU/Courses/CEU Prediction with Machine Learning for Economists/da_case_studies')

# store different directories here:
# C:/Users/thuebel/OneDrive - WU Wien/Docs/06 Courses and Study/02 Prediction with ML for Economists/da_case_studies
# C:/Users/avalder/OneDrive - WU Wien/Documents/Study/WS_23_24/Pred_MLE_Econ/da_case_studies
# C:/Users/AnjaHahn/OneDrive - DataScience Service GmbH/WU/Courses/CEU Prediction with Machine Learning for Economists/da_case_studies

```

<!-- Set directory, load functions and theme  --> 
```{r, include=FALSE}
#getwd()
source("set-data-directory.R")
source("ch00-tech-prep/theme_bg.R")
source("ch00-tech-prep/da_helper_functions.R")


data_in <- paste(data_dir,"bisnode-firms","clean/", sep = "/")
#use_case_dir <- "ch17-predicting-firm-exit/"
```

```{r,include=FALSE, warning=FALSE}
#load libraries
library(tidyverse)
library(caret)
library(ranger)
library(Hmisc)
library(knitr)
library(modelsummary)
library(treeshap)
library(summarytools)
# add
```

<!-- Load data  --> 
```{r,include=FALSE}
bisnode <- read_csv(paste(data_in,"cs_bisnode_panel.csv", sep = "/")) # 287829 obs. of 48 variables 
```

<!-- Data summary  --> 
```{r, include=FALSE}
# count missing values
colSums(is.na(bisnode))
colSums(is.na(bisnode))/nrow(bisnode)*100

# look at data
bisnode %>% glimpse()

# look at character variables
bisnode %>%
  group_by(gender) %>%
  summarise(n = n(), mean = mean(sales))

# overall summary statistics
 #descr(bisnode)

```


<!-- Sample design  --> 

```{r, include=FALSE}
####################################
# Sample design
####################################
# collect "weird stuff" here:
# Company with ID 12212152320 had a massive explosion from 2012 to 2013 (0 to 63 employees etc) - how to treat?
## did they exit before? Maybe we have to add a variable that indicate newly established firms?


# drop variables with many NAs
bisnode <- bisnode %>%        
  select(-c(COGS, finished_prod, net_dom_sales, net_exp_sales, wages, D))

# find the years with the least missing sales values
bisnode %>%
  group_by(year) %>%
  summarise(missing = sum(is.na(sales))) %>%
  arrange(missing)
# biggest sample would be 2013-2014
# NAs of all variables per year 
bisnode %>%
  group_by(year) %>%
  summarise(across(everything(), ~ mean(is.na(.)) * 100, .names = "na_share_{.col}")) %>%
  ungroup()

# generate status_alive, we only want to analyse active firms
bisnode  <- bisnode %>%
  mutate(status_alive = sales > 0 & !is.na(sales) %>%
           as.numeric(.))

# look at cross section
# add explanation to report!!!!
bisnode <- bisnode %>%
  filter(status_alive == TRUE) %>% # only look at firms that have some sales
  # look at firms below 10m euro revenues and above 1000 euros
  filter(!(sales > 10000000)) %>%
  filter(!(sales < 1000))

# add all missing year and company combinations
bisnode <- bisnode %>%
  complete(year, comp_id)
```


<!-- Data visualization  --> 

```{r, include=FALSE}
# visualize sales
plot_sales <-  ggplot(bisnode, aes(x = sales)) +
  geom_histogram(bins = 100, fill = color[1], color = color.outline, alpha = 0.8) +
  scale_x_log10() +
  labs(x = "Sales (log)", y = "Frequency")+
  theme_bg() 
plot_sales

# visualize labor_avg
plot_labor_avg <- bisnode %>% filter(labor_avg > 0) %>%
  ggplot(aes(x = labor_avg)) +
  geom_histogram(bins = 100, fill = color[1], color = color.outline, alpha = 0.8) +
  labs(x = "Average Number of Employees", y = "Frequency") +
  xlim(0, 5) +
    theme_bg() 
plot_labor_avg


```



<!-- Label engineering  --> 

```{r, include=FALSE}
####################################
# Label engineering
####################################

# generate different variations to display sales
bisnode <- bisnode %>%
  filter(status_alive == TRUE) %>% # only look at firms that have some sales
  mutate(ln_sales = log(sales), # if we want to include firms not_alive need to specially treat 0
         sales_mil=sales/1000000,
         sales_mil_log = ifelse(sales > 0, log(sales_mil), 0))
# this already windsorizes sales

# generate different variations to display labor_avg
bisnode <- bisnode %>%
  mutate(ln_labor_avg = ifelse(labor_avg > 0, log(labor_avg), 0))

###################################
# Creation of different labels: sales
###################################

# YoY relative sales growth
bisnode <- bisnode %>%
  group_by(comp_id) %>%
  arrange(year) %>%
  mutate(sales_growth_ahead = (lead(sales)/sales -1)) %>%
  ungroup()

# YoY sales growth as logdiff
bisnode <- bisnode %>%
  group_by(comp_id) %>%
  arrange(year) %>%
  mutate(d1_sales_mil_log = lead(sales_mil_log) - sales_mil_log ) %>%
  ungroup()

# 2-year ahead average annual sales growth as percentage change
# our target!!!
bisnode <- bisnode %>%
  group_by(comp_id) %>%
  arrange(year) %>%
  mutate(sales_growth_2y_ahead = (lead(sales, n = 2L)/sales -1)/2) %>%
  ungroup()

###################################
# Visualization sales growth

# make histogram that shows both sales growth and d1_sales_mil_log
plot_sales_growth_both <- ggplot(bisnode, aes(x = sales_growth_ahead)) +
  geom_histogram(aes(fill = "Percentage Change"), bins = 100, color = color.outline, alpha = 0.5) +
  geom_histogram(aes(x = d1_sales_mil_log, fill = "Log-Differences"), bins = 100, 
                 color = color.outline, alpha = 0.5) +
  scale_x_log10() +
  labs(x = "Sales growth (log)", y = "Frequency") +
  scale_fill_manual(values = c("Percentage Change" = color[1], "Log-Differences" = color[2]), 
                    name = "Growth Measures") +
  theme_bg()

plot_sales_growth_both
# It makes a difference whether relative growth is measured in log(diff) or percentage change
# since logdiff is an inaccurate approximation for high changes this is especially relevant for high growth firms

###################################
# Creation of different labels: employment
###################################
# important note: employee variables are now calculated based on lag variabes not lead variables
# hence, we can use them as features instead of target

# YoY relative employee growth
bisnode <- bisnode %>%
  group_by(comp_id) %>%
  arrange(year) %>%
  mutate(labor_growth = (labor_avg/lag(labor_avg) - 1)) %>%
  ungroup()

# YoY employee growth as logdiff
bisnode <- bisnode %>%
  group_by(comp_id) %>%
  arrange(year) %>%
  mutate(d1_labor_avg_log = ln_labor_avg - lag(ln_labor_avg) ) %>%
  ungroup()

# birch index (weighted index of absolute and relative employment growth)
bisnode <- bisnode %>%
  group_by(comp_id) %>%
  arrange(year) %>%
  mutate(birch_ind = ((labor_avg - lag(labor_avg)) * (labor_avg/lag(labor_avg) - 1)) ) %>%
  ungroup()

###################################
# Visualization employment growth

#make histogram that shows both employee growth and d1_labor_avg_log
plot_labor_growth_both <- ggplot(bisnode, aes(x = labor_growth)) +
  geom_histogram(aes(fill = "Percentage Change"), bins = 100, color = color.outline, alpha = 0.5) +
  geom_histogram(aes(x = d1_labor_avg_log, fill = "Log-Differences"), bins = 100, 
                 color = color.outline, alpha = 0.5) +
  labs(x = "Employee growth (log)", y = "Frequency") +
  scale_fill_manual(values = c("Percentage Change" = color[1], "Log-Differences" = color[2]), 
                    name = "Growth Measures") +
  scale_x_log10() #+
  # theme_bg()
plot_labor_growth_both

# make histogram of birch index
plot_birch_ind <- ggplot(bisnode, aes(x = birch_ind)) +
  geom_histogram(bins = 100, fill = color[1], color = color.outline, alpha = 0.8) +
  labs(x = "Birch Index", y = "Frequency") +
  theme_bg() +
  scale_x_log10()
plot_birch_ind


###################################
# Overwrite d1_sales_mil log to lagged variables since we will not use it as target but might inclzude it as predictor
# YoY sales growth as logdiff
bisnode <- bisnode %>%
  group_by(comp_id) %>%
  arrange(year) %>%
  mutate(d1_sales_mil_log = sales_mil_log - lag(sales_mil_log) ) %>%
  ungroup()


# show the number of NA in the variable growth_2y_ahead for each year
x <-bisnode %>%
  group_by(year) %>%
  summarise(na_count = sum(is.na(sales_growth_2y_ahead)))


###################################
# Define Cutoff for High Growth firms
###################################

# Look at good cutoff for high growth
quantile(bisnode$sales_growth_2y_ahead, na.rm = TRUE, probs = seq(0, 1, 0.05))

# define high growth firms as firms that grow with more than 30% (coincides with fastest 20% in our data set)
bisnode <- bisnode %>%
  mutate(high_growth = ifelse(sales_growth_2y_ahead > 0.3, 1, 0))

####################################
# notes on growth
####################################
# different types of growth
# yoy relative growth in sales
# average yoy relative growth in sales over 2 years
# yoy relative growth in employees
# average yoy relative growth in employees over 2 years

# cutoff:
# classify as "fast" if they meet a combination of the above?
# OECD definition: 20% average growth in sales or employees over 3 years
# do the same but only with 2 years? Anne: sounds good and justified to me!

# in literature it has been suggested to use fastest growing percintile 8e.g. to 5% of firms)
# see: https://www.diva-portal.org/smash/get/diva2:605658/FULLTEXT01.pdf
# rather than hard cutoff --> but not meaningful for us if we want to compare growth in different industries
# a lot of firms with 0-1 employees: might need a lower absolute threshold for growth such that tiny firms that
# add one extra employee are not classified as fast growing?
```



^23 <!-- Filter for 2012  --> 

```{r}
# restrict sample to 2012 for further analysis

bisnode <- bisnode %>%
  filter(year == 2012)

```


<!-- Feature engineering  --> 

```{r, include=FALSE}
# re-code one character variable
bisnode <- bisnode %>%
  mutate(urban_m = case_when(
      urban_m == 1 ~ "capital_city",
      urban_m == 2 ~ "other_big_city",
      urban_m == 3 ~ "other"))

# convert character variables to factors 
bisnode <- bisnode %>% 
  mutate_if(is.character, as.factor)

# classify industry categories as factors
bisnode <- bisnode %>%
  mutate(across(all_of(c("ind", "ind2", "nace_main")), as.factor))

###################################
# new variables
# firm characteristics
bisnode <- bisnode %>%
  mutate(age = (year-founded_year) %>% # maybe remove again if computed earlier
           ifelse(. < 0, 0, .),
         age2 = age^2,
         new = as.numeric(age <= 1),
         foreign_management = as.numeric(foreign >= 0.5),
         multiple_ceo = as.numeric(ceo_count > 1),
         ceo_age = (year-round(birth_year))) # avoid digits for years

###################################
# plausibility checks of relevant numeric variables
for (var in c("age", "ceo_age", "ceo_count", "tang_assets",
             "curr_assets", "curr_liab", "extra_exp", "extra_inc",
             "extra_profit_loss", "fixed_assets", "inc_bef_tax",
             "intang_assets", "inventories", "liq_assets", "material_exp",
             "personnel_exp", "profit_loss_year", "share_eq", "subscribed_cap")){
  print(paste(paste0(var, 
                     ": min:", 
                     min(bisnode[, var], na.rm = TRUE), 
                     "; max:"),
              max(bisnode[, var], na.rm = TRUE)))
}
rm(var)

###################################
# problematic data
# age CEO cannot be negative, also some too young
bisnode <- bisnode %>%
  mutate(ceo_age = ifelse(ceo_age < 18, NA, ceo_age)) # overwrite implausible ones with NA for now

# there cannot be negative financial variables
zero <- c("curr_liab", "curr_assets", "extra_exp", "extra_inc", "fixed_assets",
          "intang_assets", "inventories", "liq_assets", "material_exp",
          "personnel_exp", "subscribed_cap", "tang_assets")

# flag negative ones
for (var in zero){
  aux <- paste0(var, "_flag_error")
  bisnode[, aux] <- as.numeric(bisnode[, var] < 0)
}

# flag any negative assets 
# (extra variable for calculating total assets later)
bisnode <- bisnode %>%
  mutate(flag_asset_problem = ifelse(intang_assets < 0 | curr_assets < 0 | fixed_assets < 0, 1, 0))

# set negative ones to zeros
bisnode <- bisnode %>%
  mutate_at(vars(zero), funs(ifelse(. < 0, 0, .)))


###################################
# NA analysis and imputation
colSums(is.na(bisnode))/nrow(bisnode)*100

# drop missing important variables
# drops about 20%
bisnode <- bisnode %>%
  filter(!is.na(liq_assets), # representative of missing assets data
         !is.na(foreign), # representative of missing CEO data
         !is.na(ind), # representative of industry data (removes many NACE 2-digit categories)
         !is.na(region_m), # geographical info
         !is.na(age),
         !is.na(material_exp)) 


# impute important ones
# ceo age
bisnode <- bisnode %>%
  mutate(flag_missing_ceo_age = as.numeric(is.na(ceo_age)),
         ceo_age = round(ifelse(is.na(ceo_age), mean(ceo_age, na.rm = TRUE), ceo_age)))

# number of employees
bisnode <- bisnode %>%
  mutate(flag_miss_labor_avg = as.numeric(is.na(labor_avg)),
         labor_avg = ifelse(is.na(labor_avg), mean(labor_avg, na.rm = TRUE), labor_avg))

# sales
# add sales

# re-compute transformed labor/sales vars

# still existing NAs

for (var in names(bisnode)){
  
  if(any(is.na(bisnode[, var]))){
    print(paste0(var, ":", sum(is.na(bisnode[, var]))/nrow(bisnode)*100))
  }
}
rm(var)

###################################
# new variables and 
# variable transformation

# group some industry category codes (2-digit NACE)
# after NA removal, categories have decreased considerably to
# manufactoring and services industries
table(bisnode$ind2)
bisnode <- bisnode %>%
  mutate(ind2_cat = factor(case_when(
    ind2 %in% c("26", "27", "28", "29", "30", "33") ~ "manufacturing",
    ind2 %in% c("55", "56") ~ "services"
  )))

# calculate new age ceo variable
bisnode <- bisnode %>%
  mutate(ceo_young = as.numeric(ceo_age < 40 & !is.na(ceo_age)),
         ceo_old = as.numeric(ceo_age > 75 & !is.na(ceo_age)))

# generate total assets
bisnode <- bisnode %>%
  mutate(total_assets = intang_assets + curr_assets + fixed_assets)

# compute relative variables (sales as reference)
bisnode <- bisnode %>%
  mutate_at(vars("extra_exp", "extra_inc", "extra_profit_loss", 
                 "inc_bef_tax", "inventories", "material_exp",
                 "profit_loss_year", "personnel_exp"),
            funs("rel" = ./sales))

# compute relative variables (total assets as reference)
bisnode <- bisnode %>%
  mutate_at(vars("intang_assets", "curr_liab", "fixed_assets", 
                 "liq_assets", "curr_assets", "share_eq", 
                 "subscribed_cap", "tang_assets"),
            funs("rel" = ifelse(total_assets == 0, 0, ./total_assets)))


######################################
# creating flags and winsorizing tails

# overwrite selected variables with relative ones
zero <- paste0(zero, "_rel")

# flag very high observations and set them to 1
bisnode <- bisnode %>%
  mutate_at(vars(zero), funs("flag_high"= as.numeric(. > 1))) %>%
  mutate_at(vars(zero), funs(ifelse(. > 1, 1, .)))

# for vars that could be any (also negative), but are mostly between -1 and 1
any <-  c("extra_profit_loss_rel", "inc_bef_tax_rel", "profit_loss_year_rel", "share_eq_rel")

# add flags and set tails to -1/1 and add quadratics
bisnode <- bisnode %>%
  mutate_at(vars(any), funs("flag_low" = as.numeric(. < -1))) %>%
  mutate_at(vars(any), funs(ifelse(. < -1, -1, .))) %>%
  mutate_at(vars(any), funs("flag_high" = as.numeric(. > 1))) %>%
  mutate_at(vars(any), funs(ifelse(. > 1, 1, .))) %>%
  mutate_at(vars(any), funs("flag_zero" = as.numeric(. == 0))) %>%
  mutate_at(vars(any), funs("quad" = .^2))

# dropping flags with no variation
variances <- bisnode %>%
  select(contains("flag")) %>%
  apply(2, var, na.rm = TRUE) == 0
bisnode <- bisnode %>%
  select(-one_of(names(variances)[variances]))

# sales
# add lag!!
bisnode <- bisnode %>%
  mutate(sales_mil_log_sq=sales_mil_log^2)

bisnode <- bisnode %>%
  mutate(flag_low_d1_sales_mil_log = ifelse(d1_sales_mil_log < -1.5, 1, 0),
         flag_high_d1_sales_mil_log = ifelse(d1_sales_mil_log > 1.5, 1, 0),
         d1_sales_mil_log_mod = ifelse(d1_sales_mil_log < -1.5, -1.5,
                                       ifelse(d1_sales_mil_log > 1.5, 1.5, d1_sales_mil_log)),
         d1_sales_mil_log_mod_sq = d1_sales_mil_log_mod^2
         )

```



```{r}
########################################
# relationships between variables

# scatterplot computation
plots <- list()

# relevant numeric vars
vars_num <- c(zero, any, c("total_assets", "ceo_age", "age", "labor_avg"))
# add sales/labour var!!!

# check relationships
for (var in vars_num){
  
  if(any(is.na(bisnode[, var]))){
    print(paste0(var, " entails NAs")) # check for lowess
  } else{
    plots[[var]] <- ggplot(data = bisnode, aes_string(x = var, y = "high_growth")) +
  geom_point(size = 0.1,  shape = 20, fill = color[2], color = color[2]) +
  geom_smooth(method = "loess", se = F, colour = color[1], size = 1.5, span = 0.9) +
  theme_bg()
  }
}

# choose plots to show
plots$curr_assets_rel
plots[[15]]

# check lm with quadratics
glm_results <- list()

for (var in vars_num){
  
  # build the formula dynamically
  formula <- formula(paste0("high_growth ~ ", var, " + I(", var, "^2)"))
  
  glm <- glm(formula, data = bisnode, family = "binomial")
  glm_results[[var]] <- summary(glm)
  
}

# ?? 1, 5, 6, 7, 8, 11 # add lm to check signficance!!!
# 4, 10, 12, 13, 15

# add quadratics yes or no? all variables considered? winsorise more?
quad <- c("curr_liab_rel", "curr_assets_rel",
          "intang_assets_rel", "inc_bef_tax_rel", "total_assets", "ceo_age")

bisnode <- bisnode %>%
  mutate_at(vars(quad), funs("quad"= .^2))


# response vs. binary and factor variables
binary_variables <- c("gender", "origin", "ind2", "ind", "ind2_cat", "urban_m",
                      "region_m", "ceo_old", "ceo_young")


# loop did not work
ggplot(bisnode, aes(x = factor(gender), fill = factor(high_growth))) +
# ggplot(bisnode, aes(x = factor(ceo_old), fill = factor(high_growth))) +
# ggplot(bisnode, aes(x = factor(ceo_young), fill = factor(high_growth))) +
    geom_bar(position = "fill", stat = "count") +
      labs(y = "Proportion", fill = "Fast Growth") +
  theme_bg() +
  scale_fill_manual(values = c(color[1], color[2]))


# interactions
interactions_plot <- ggplot(bisnode, aes(x = labor_avg, y = high_growth, color = ind2)) +
  # ggplot(bisnode, aes(x = age, y = high_growth, color = ind2_cat)) +
  theme_bw() + 
  geom_point() + 
  geom_point(alpha = .3, 
             size = .9) +
  geom_smooth(method = "lm") #+ 
  # scale_color_manual(values = c(color[1], color[2]))

# drop unused factor levels
bisnode <- bisnode %>%
  mutate(across(where(is.factor), ~ droplevels(.)))

# check remaining data
colSums(is.na(bisnode))/nrow(bisnode)*100
# datasummary_skim(bisnode, type='numeric', histogram = TRUE)


```


<!-- Task1.1: Define variable groups for differnet models  --> 

```{r}
######  Adjust for our variables!!! Most are similar & add ours
## maybe Anja you have a better overview what we used
# female? or gender variable?
# all sales and labor vars?
# ind2 keep?problems with one hot encoding - many vars
# flags
# total_assets_rel?? curr_liab_rel?? tang_assets_rel??

rawvars <-  c("curr_assets", "curr_liab", "extra_exp", "extra_inc", "extra_profit_loss", 
              "fixed_assets", "inc_bef_tax", "intang_assets", "inventories", "liq_assets", 
              "material_exp", "personnel_exp", "profit_loss_year", "sales", "share_eq", 
              "subscribed_cap")

qualityvars <- c("balsheet_flag", "balsheet_length", "balsheet_notfullyear")

engvar <- c("total_assets", "fixed_assets_rel", "liq_assets_rel", "curr_assets_rel",
            "share_eq_rel", "subscribed_cap_rel", "intang_assets_rel", "extra_exp_rel",
            "extra_inc_rel", "extra_profit_loss_rel", "inc_bef_tax_rel", "inventories_rel",
            "material_exp_rel", "profit_loss_year_rel", "personnel_exp_rel", 
            "curr_liab_rel")

# add additional quadratics!!
engvar2 <- c("extra_profit_loss_rel_quad", "inc_bef_tax_rel_quad",
             "profit_loss_year_rel_quad", "share_eq_rel_quad", 
             "intang_assets_rel_quad", "total_assets_quad",
             "ceo_age_quad")

engvar3 <- c(grep("*flag_low$", names(bisnode), value = TRUE),
             grep("*flag_high$", names(bisnode), value = TRUE),
             grep("*flag_error$", names(bisnode), value = TRUE),
             grep("*flag_zero$", names(bisnode), value = TRUE))
# do not add flag_assets_problem due to missing variation

# are below variables there??
d1 <-  c("d1_sales_mil_log_mod", "d1_sales_mil_log_mod_sq",
         "flag_low_d1_sales_mil_log", "flag_high_d1_sales_mil_log")

hr <- c("ceo_old", "ceo_young", "ceo_age", "flag_missing_ceo_age", 
        "ceo_count", "gender", "multiple_ceo", "foreign_management",
        "labor_avg", "flag_miss_labor_avg")

firm <- c("age", "age2", "new")

# factors <- c("gender", "origin", "ind", "ind2", "ind2_cat", "region_m", "urban_m")

# dummy_encoded <- c("gender.male", "gender.mix", "origin.Foreign", "origin.mix", "region_m.East", "region_m.West", "urban_m.other", "urban_m.other_big_city", "ind.2", "ind.3", "ind2_cat.services")


# interactions for logit, LASSO
interactions1 <- c("ind2_cat*age", "ind2_cat*age2",
                   "ind2_cat*d1_sales_mil_log_mod", "ind2_cat*sales_mil_log",
                   "ind2_cat*ceo_age", "ind2_cat*foreign_management",
                   "ind2_cat*female",   "ind2_cat*urban_m", "ind2_cat*labor_avg_mod")
interactions2 <- c("sales_mil_log*age", "sales_mil_log*female",
                   "sales_mil_log*profit_loss_year_pl", "sales_mil_log*foreign_management")


X1 <- c("sales_mil_log", "sales_mil_log_sq", "d1_sales_mil_log_mod", "profit_loss_year_pl", "ind2_cat")
X2 <- c("sales_mil_log", "sales_mil_log_sq", "d1_sales_mil_log_mod", "profit_loss_year_pl", "fixed_assets_bs","share_eq_bs","curr_liab_bs ",   "curr_liab_bs_flag_high ", "curr_liab_bs_flag_error",  "age","foreign_management" , "ind2_cat")
X3 <- c("sales_mil_log", "sales_mil_log_sq", firm, engvar,                   d1)
X4 <- c("sales_mil_log", "sales_mil_log_sq", firm, engvar, engvar2, engvar3, d1, hr, qualityvars)
X5 <- c("sales_mil_log", "sales_mil_log_sq", firm, engvar, engvar2, engvar3, d1, hr, qualityvars, interactions1, interactions2)

# for Logit
logitvars <- c("sales_mil_log", "sales_mil_log_sq", engvar, engvar2, engvar3, d1, hr, firm, qualityvars, interactions1, interactions2)

# for RF (no interactions, no modified features)
rfvars  <-  c("sales_mil", "d1_sales_mil_log", rawvars, hr, firm, qualityvars)

# for Logit LASSO:


# Check simplest model X1

```


<!-- Preparation for prediction & CV  --> 

```{r,include=FALSE}
set.seed(123456)

######CHANGE TARGET VAR (make interchangable!)
work_indices <- as.integer(createDataPartition(bisnode$sales, p = 0.8, list = FALSE))
bisnode_work <- bisnode[work_indices, ]
bisnode_holdout <- bisnode[-work_indices, ]

dim(bisnode_work)
dim(bisnode_holdout)

# separation into train and test automatically via cross-validation using caret package

n_folds = 5
train_control <- trainControl(method = "cv",
                              number = n_folds,
                              classProbs = TRUE, # computing probabilities during training
                              summaryFunction = twoClassSummaryExtended, # from da_helper_functions.R
                              savePredictions = TRUE # save the predictions for each fold
                              )
# train_control$verboseIter <- TRUE # add that for RF, if we want to see calculation steps
```

<!-- Task1.1: Model 1 - Logit  --> 

```{r}
#######################################################
# PART I PREDICT PROBABILITIES
# Predict logit model ----------------------------------------------
#######################################################

# No loss function
# RMSE (AUC also?based on threshold that corresponds to prevalence of pos/neg in dataset)

# Train Logit Models ----------------------------------------------
## keep maybe for shiny vut decide which is our main model!
logit_model_vars <- list("X1" = X1, "X2" = X2, "X3" = X3, "X4" = X4, "X5" = X5)

CV_RMSE_folds <- list()
logit_models <- list()

for (model_name in names(logit_model_vars)) {

  features <- logit_model_vars[[model_name]]
###CHNAGE TRAGET
  set.seed(13505)
  glm_model <- train(
    formula(paste0("sales ~", paste0(features, collapse = " + "))),
    method = "glm",
    data = bisnode_work,
    family = binomial,
    trControl = train_control
  )

  logit_models[[model_name]] <- glm_model
  # Calculate RMSE on test for each fold
  CV_RMSE_folds[[model_name]] <- glm_model$resample[,c("Resample", "RMSE")]

}
#### MAYBE DELETE DO SMALLER IF WE ONLY WANT ONE LOGIT!
#############################################x
# PART I
# No loss fn
########################################

# Draw ROC Curve and calculate AUC for each folds --------------------------------
CV_AUC_folds <- list()

for (model_name in names(logit_models)) {

  auc <- list()
  model <- logit_models[[model_name]]
  for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
    cv_fold <-
      model$pred %>%
      filter(Resample == fold)

    roc_obj <- roc(cv_fold$obs, cv_fold$default)
    auc[[fold]] <- as.numeric(roc_obj$auc)
  }

  CV_AUC_folds[[model_name]] <- data.frame("Resample" = names(auc),
                                              "AUC" = unlist(auc))
}

# For each model: average RMSE and average AUC for models ----------------------------------

CV_RMSE <- list()
CV_AUC <- list()

for (model_name in names(logit_models)) {
  CV_RMSE[[model_name]] <- mean(CV_RMSE_folds[[model_name]]$RMSE)
  CV_AUC[[model_name]] <- mean(CV_AUC_folds[[model_name]]$AUC)
}

# Take best model and estimate RMSE on holdout  -------------------------------------------

best_logit_no_loss <- logit_models[["X4"]]

logit_predicted_probabilities_holdout <- predict(best_logit_no_loss, newdata = bisnode_holdout, type = "prob")
bisnode_holdout[,"best_logit_no_loss_pred"] <- logit_predicted_probabilities_holdout[,"TARGET"]
RMSE(bisnode_holdout[, "best_logit_no_loss_pred", drop=TRUE], bisnode_holdout$TARGET)

```

<!-- Task1.1: Model 2 - Probability forest  --> 

```{r}
#################################################
# Probability forest
# Split by gini, ratio of 1's in each tree, average over trees
#################################################

tune_grid <- expand.grid(
  .mtry = c(5, 6, 7),
  .splitrule = "gini",
  .min.node.size = c(10, 15))

# getModelInfo("ranger")
#### chnage TARGET 
rf_model_p <- train(
  formula(paste0("TARGET ~ ", paste0(rfvars , collapse = " + "))),
  method = "ranger",
  data = bisnode_work,
  tuneGrid = tune_grid,
  trControl = train_control
)

rf_model_p$results

best_mtry <- rf_model_p$bestTune$mtry
best_min_node_size <- rf_model_p$bestTune$min.node.size

# Get average (ie over the folds) RMSE and AUC ------------------------------------
CV_RMSE_folds[["rf_p"]] <- rf_model_p$resample[,c("Resample", "RMSE")]

auc <- list()
for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
  cv_fold <-
    rf_model_p$pred %>%
    filter(Resample == fold)

  roc_obj <- roc(cv_fold$obs, cv_fold$default)
  auc[[fold]] <- as.numeric(roc_obj$auc)
}
CV_AUC_folds[["rf_p"]] <- data.frame("Resample" = names(auc),
                                         "AUC" = unlist(auc))

CV_RMSE[["rf_p"]] <- mean(CV_RMSE_folds[["rf_p"]]$RMSE)
CV_AUC[["rf_p"]] <- mean(CV_AUC_folds[["rf_p"]]$AUC)

# Now use loss function and search for best thresholds and expected loss over folds -----### SECOND PART 
```




<!-- Task1.1: Model 3 - Logit LASSO?? / Classification Tree?  -->
```{r}
# Logit lasso -----------------------------------------------------------

lambda <- 10^seq(-1, -4, length = 10)
grid <- expand.grid("alpha" = 1, lambda = lambda)

system.time({
  logit_lasso_model <- train(
    formula(paste0("TARGET ~", paste0(logitvars, collapse = " + "))),
    data = bisnode_work,
    method = "glmnet",
    preProcess = c("center", "scale"),
    family = "binomial",
    trControl = train_control,
    tuneGrid = grid,
    na.action=na.exclude
  )
})

tuned_logit_lasso_model <- logit_lasso_model$finalModel
best_lambda <- logit_lasso_model$bestTune$lambda
logit_models[["LASSO"]] <- logit_lasso_model
lasso_coeffs <- as.matrix(coef(tuned_logit_lasso_model, best_lambda))
#write.csv(lasso_coeffs, paste0(output, "lasso_logit_coeffs.csv"))

CV_RMSE_folds[["LASSO"]] <- logit_lasso_model$resample[,c("Resample", "RMSE")]


# ALTERNATIVE
#################################################
# Classification forest
# Split by Gini, majority vote in each tree, majority vote over trees
#################################################
```




<!-- Task1.1: Evaluation  -->
```{r}

# discrete ROC (with thresholds in steps) on holdout -------------------------------------------------
# continuous ROC on holdout with best model (Logit 4) -------------------------------------------
# Confusion table with different tresholds ----------------------------------------------------------
# Calibration curve -----------------------------------------------------------

## ADD
```


<!-- Task1.2: Loss function design -->


```{r}

#############################################x
# PART II.
# We have a loss function
########################################
```


<!-- Task1.2: For each of the three models: predict probabilities, look for the optimal classification threshold, calculate expected loss with your loss function  -->
<!-- Task1.2: Pick model with smallest expected loss -->
```{r}

```

<!-- Task1.3: Show a confusion table (on a selected fold or holdout set) -->
<!-- Task1.3: Discuss results, evaluate how useful your model may be -->
```{r}

```

<!-- Task2.1: 2 Samples (service & manufacturing)  --> 

```{r}

```
<!-- Task2.2: Define single loss function (Same loss function as before?) but use for samples separately (pick one prediction model) --> 

```{r}

```

<!-- Task2.3: Compare the model performance across two samples -->

```{r}

```

<!-- Task3.1: Use some methods to interpret your random forest probability model (Shapley, PDP) --> 

```{r}
# ideas:
# Feature importance plot
varImpPlot(rf_model)
# Install and load 'pdp' package if not already installed
# install.packages("pdp")
library(pdp)

# Partial dependence plot for 'var1'
partial_plot <- partial(rf_model, pred.var = "var1", grid.resolution = 100)
plot(partial_plot)

# Install and load 'vip' package if not already installed
# install.packages("vip")
library(vip)

# Permutation feature importance
vip(rf_model)

# Install and load 'shap' package if not already installed
# install.packages("shap")
library(shap)
########################################
# one-hot encoding of additional factors
dmy <- dummyVars("~ ind + ind2 + ind2_cat + gender + origin + region_m + urban_m", 
                 data = bisnode, fullRank = TRUE)
new_dat <- data.frame(predict(dmy, newdata = bisnode))
# add new variables to data
bisnode <- cbind(bisnode, new_dat)
rm(new_dat)

# Extract SHAP values
shap_values <- predict_contrib(rf_model, holdout_set)

# Summary plot of SHAP values
shap_summary_plot(shap_values, holdout_set)

# Explanation for a specific observation (replace 'index' with the actual index)
shap_values_single <- predict_contrib(rf_model, holdout_set[index, ])
shap_plot(shap_values_single)
```


<!-- Task3.2: Create a shiny (flexdashboard) app for the project where you can show (1) how key variables influence the prediction (!Shapley) and (2) show expected loss based on different thresholds. -->