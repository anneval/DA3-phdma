---
title: "Assignment 2 - Airbnb prediction models"
subtitle: "Course: ECBS6067 - Prediction with Machine Learning for Economists"
author: "Anne Valder"
date: "2023-12-02"
output:
  pdf_document: default
  html_document:
  df_print: paged
---
<!-- TO DO: clean up test/train/hold out ML part....
Transform DKK to EUR SEE if RMSE drops--> 
```{r setup, include=FALSE}
# Set options for markdown
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = 'C:/Users/avalder/OneDrive - WU Wien/Documents/Study/WS_23_24/Pred_MLE_Econ/da_case_studies')
```

```{r,include=FALSE}
# Clear memory
rm(list=ls())

#load libraries
library(rattle)
library(tidyverse)
library(caret)
library(ranger)
library(Hmisc)
library(knitr)
library(kableExtra)
library(xtable)
```
<!-- Set directory, load functions and theme  --> 
```{r, include=FALSE}
#getwd()
source("set-data-directory.R")
source("ch00-tech-prep/theme_bg.R")
source("ch00-tech-prep/da_helper_functions.R")
```
<!-- Load data  --> 
```{r,include=FALSE}
#  
# Copenhagen 24 September, 2023 (data for prediction)
listings_Sep <- read.csv(paste0(data_dir,"/airbnb/assignment/listings_cph_SEP23.csv"), sep = ",", header = T, stringsAsFactors = F)

# Copenhagen 29 December, 2022 (data for model estimation)
listings_Dec <- read.csv(paste0(data_dir,"/airbnb/assignment/listings_cph_DEC22.csv"), sep = ",", header = T, stringsAsFactors = F)

# check whether the two data set from the different review dates differ 
check_equal_columns <- function(df1, df2) {
  cols_df1 <- names(df1)
  cols_df2 <- names(df2)
  
  if (all.equal(cols_df1, cols_df2)) {
    cat("Both data frames have the same columns.\n")
    return(TRUE)
  } else {
    cat("The data frames have different columns.\n")
    return(FALSE)
  }
}

check_equal_columns(listings_Sep, listings_Dec)

# Add a new column to each data set to identify their origin
listings_Sep$origin <- "Sep 23"
listings_Dec$origin <- "Dec 22"

# Combine the data sets
listings <- rbind(listings_Sep, listings_Dec)
# define for saving the data later
use_case_dir <- "A2/"
data_out <- use_case_dir
```
**The report below summarizes pricing strategies for small and mid-size apartments in Copenhagen. Using a data-driven approach, I determine that the average price for apartments hosting 2 to 6 guests is 300 DKK per night, as predicted by the best-performing model. The driving factors influencing apartment prices are the number of beds and the neighborhood.** The first part of the report delves into data preparation and pre-processing. Subsequently, the three distinct price prediction models, along with all modeling decisions, are explained. This is followed by a comparison of the results with predicted apartment prices in London. In addition, to further assess the predictive power of the models out of sample, predictions are made not only on a holdout set but also on an additional data set covering a different time frame, essentially mimicking live data. Finally, the report provides a detailed evaluation of the model performance of the best-performing machine learning model, utilizing variance-important measures such as Shapely values and partial dependence plots.

**Data Preparation:**The data for apartments in Copenhagen is taken from [Inside Airbnb](http://insideairbnb.com/get-the-data/). The selected data sets include the review date 24 September, 2023 and the review date 29 December, 2022. After joining the data sets, I proceed with the *sample design* as follows. First, I drop variables that are of no use to the prediction exercise, e.g. variables containing urls, or specifics about the host etc. Next, I make sure that all variables are cleaned (i.e. remove characters or symbols) and of the correct type and class for the prediction exercise (e.g. conversion to binary, numeric and factors). Moreover, I encode the 'price' variable to have the right format (no commas for thousands). Furthermore, I transform the variable 'amenity', which originally contains a listing of all kinds of amenities a certain Airbnb has, into dummy variables. In order to prevent to obtain over 2000 dummy variables I group the most important amenities together and create approximately 15 dummies. In order to ensure that the sample relates to the policy question at hand I filter for apartments that can house only 2 to 6 people and that correspond to "standard" property types for representative Airbnb prices. To circumvent that the analysis is distorted by errors I drop extreme values by making sure that the minimum number of nights is at leas equal to one. At last I create the variable 'days since first review' which allows me to analyse approximately for how long the apartments have been used as a Airbnbs.
```{r, echo=FALSE, include=FALSE}
# Sample Design:

#1) drop all variables in listings file that are redundant, lots of url variables or descriptive, or host related variables.

drop_variables <- c("host_thumbnail_url","host_picture_url","listing_url","picture_url","host_url","last_scraped","description", "neighborhood_overview", "host_about", "host_response_time", "name", "host_location","neighbourhood_group_cleansed","source","license","calendar_updated") # drop similar variables to airbnb_london_cleaner.R. Either not needed or only contains NAs..

listings <- listings %>% select(-drop_variables)

#2) check if id variables contain at least one alphabetical character, if yes drop those
listings$junk<-grepl("[[:alpha:]]", listings$id)
summary(as.factor(listings$junk))
listings <-subset(listings,junk==FALSE)
listings <- listings %>% select(-junk) 

#3) check all classes and variable types of data sets
sapply(listings, class)
sapply(listings, typeof)

#4) remove percentage & dollar signs
remove_symbols <- function(x) {
  #remove either dollar sign or percentage sign
  value_clean <-  gsub("[$%]", "", x)
  # convert value to numeric
   if (length(value_clean) > 1) {
    return(value_clean)
  } else {
    return(as.numeric(value_clean))
  }}

## apply the function to all columns in the data frame

listings_clean <- listings %>% mutate_all(.funs = remove_symbols)

#5) Some of the input values in price are improperly formatted due to the presence of commas (i.e.,) between the numbers. Using the gsub function, we can remove these commas.

listings_clean <- listings_clean %>% 
  mutate(price_n = gsub(",", "", price),
         price_n = as.numeric(price_n))

#6) format binary variables
## function to convert "f" and "t" to 0 and 1
convert_binary <- function(x) {
  ifelse(toupper(x) == "T", 1, ifelse(toupper(x) == "F", 0, x))
}

# apply the function to all columns in the data frame
listings_clean <- listings_clean %>%
  mutate_all(.funs = convert_binary)

#7) add numeric columns from certain columns

vars_to_convert <- c("host_id","id","scrape_id","maximum_nights","minimum_nights","accommodates","bathrooms","review_scores_rating","number_of_reviews","reviews_per_month","beds","host_is_superhost","host_listings_count","host_total_listings_count","host_has_profile_pic","host_identity_verified","latitude","longitude","minimum_minimum_nights","maximum_minimum_nights","minimum_maximum_nights","maximum_maximum_nights","minimum_nights_avg_ntm","maximum_nights_avg_ntm","has_availability","availability_30","availability_60","availability_90", "availability_365","number_of_reviews","bedrooms")

listings_clean <- listings_clean %>% 
    mutate(across(all_of(vars_to_convert), as.numeric))
```

```{r, echo=FALSE, include=FALSE}
#8) create dummies for amenities (would create over 2000 variables). Therefore, group manually most important ones and create some dummies. 
# Extract amenities from the text and create dummy variables
extract_and_group_amenities <- function(data) {
  data %>%
    mutate(amenities = gsub('\\[|\\]|"', '', amenities)) %>%
    separate_rows(amenities, sep = ',\\s*') %>%
    mutate(amenities = trimws(amenities)) %>%
    # Remove strings starting with "\u" in the amenities column
    mutate(amenities = gsub('^\\\\u.*', '', amenities)) %>%
    filter(amenities != "") %>%  # Remove empty strings after removal
    mutate(amenity_type = case_when(
      grepl("Wifi", amenities) ~ "a_Internet",
      grepl("Washer|Dryer|Laundromat nearby|Drying rack for clothing|Iron", amenities) ~ "a_Laundry",
      grepl("Kitchen|Microwave|Refrigerator|Dishes and silverware|Toaster|Freezer|Stove|Oven|Cooking basics",  
            amenities) ~ "a_Kitchen",
      grepl("Espresso machine|French press|Hot water|Coffee maker: pour-over coff#ee", amenities) ~ "a_TeaCoffee",
      grepl("Heating", amenities) ~ "a_Heating",
      grepl("Pets allowed", amenities) ~ "a_Petfriendly",
      grepl("Parking|Paid street parking off premises", amenities) ~ "a_Parking",
      grepl("Balcony|Outdoor furniture|Backyard|Private patio or balcony", amenities) ~ "a_OutdoorArea",
      grepl("Soap|Shampoo|Hair dryer|Shower gel|Body soap|Conditioner", amenities) ~ "a_Toiletry",
      grepl("TV with standard cable|TV|Netflix|Disney+|Chromecast|HBO Max|sound system|Bluetooth", amenities) ~ 
            "a_Entertainment",
      grepl("Changing table|High chair|Baby bath", amenities) ~ "a_Childfriendly",
      grepl("Dedicated workspace", amenities) ~ "a_HomeOffice",
      grepl("Long term stays allowed", amenities) ~ "a_LongTermStay",
      grepl("Self check-in|Keypad", amenities) ~ "a_Selfcheckin",
      grepl("Smoke alarm", amenities) ~ "a_Security",
      grepl("Cats", amenities) ~ "a_cats",
      grepl("Dogs", amenities) ~ "a_dogs",
      TRUE ~ "Other_Group"
    )) %>%
    pivot_wider(names_from = amenity_type, values_from = amenities, values_fn = length, values_fill = 0) %>%
    mutate(across(starts_with("a_"), ~ifelse(. > 0, 1, 0)))
}

listings_clean <- extract_and_group_amenities(listings_clean)
# drops the amenities column automatically by storing into "other_group"
```

```{r, echo=FALSE, include=FALSE}
# adjust sample according to policy question:
#9) filter n accommodate 2-6 according to policy question 
summary(as.factor(listings_clean$accommodates))
listings_clean <- listings_clean %>%
  filter(accommodates >= 2 & accommodates <= 6 )

#10) drop extreme values in terms of duration?
# filter min night at least 1 to delete errors
listings_clean <- listings_clean %>% 
    filter(minimum_nights <= 7 & minimum_nights >= 1)

#11) keep only if  certain "standard" property types for representative Airbnb prices (probably extra cost for special Airbnbs like Boats etc.)
summary(as.factor(listings_clean$property_type))

listings_clean <- listings_clean %>%
  filter(property_type %in% c("Entire rental unit","Entire home","Entire loft","Entire serviced apartment","Entire villa","Entire condo","Private room in condo","Private room in home","Private room in rental unit","Private room in townhouse","Entire townhouse")) %>%
  mutate(f_property_type = factor(property_type))

#12) room type as factor 
table(listings_clean$room_type)
listings_clean <- listings_clean %>%
  mutate(f_room_type = factor(room_type))

#13) rename room type because of length 
listings_clean$f_room_type2 <- factor(ifelse(listings_clean$f_room_type== "Entire home/apt", "Entire/Apt",
                            ifelse(listings_clean$f_room_type== "Private room", "Private",
                                   ifelse(listings_clean$f_room_type== "Shared room", "Shared", "."))))

#14) create days since first review
listings_clean <- listings_clean %>%
  mutate(
    n_days_since = as.numeric(as.Date(calendar_last_scraped,format="%Y-%m-%d") -
                                as.Date(first_review ,format="%Y-%m-%d")))
```
In terms of *label engineering* I make sure that minimum and maximum values are reasonable and drop extreme values above 15.000 DKK (i.e. 2000 Euro per night) which are likely to be errors after carefully considering the characteristics of those high-priced Airbnbs. Moreover, I check whether a log-transformation is feasible, since 
it might be interesting to analyse relative changes rather than changes per monetary unit. The two graphs in the appendix however show that transforming the target variable to logs does not alter the shape of the distribution significantly. Therefore, I continue to use the target variable in levels.   
```{r, echo=FALSE, include=FALSE, warning=FALSE}
### Label engineering
#1) keep Airbnbs with price info only
summary(listings_clean$price_n)
listings_clean <- listings_clean %>%
  drop_na(price)

#2) drop extreme values in terms of price
summary(listings_clean$price_n)
# min is 75 DKK which is approx 10EUR and max is 150368DKK which is 20166,60 EUR
# Drop everything above 15000DKK (i.e. 2000EUR) 
listings_clean <- listings_clean %>% 
  filter(price_n <=  15000) %>% 
  mutate(price_ln = log(price_n))

#3 log price or not look at each distribution 
p1_lnprice <- ggplot(listings_clean, aes(price_ln)) +
  geom_histogram(binwidth = 0.15, fill = color[1], color = color.outline, alpha = 0.8, size = 0.25) +
  ylab("Count") +
  xlab("Log price") +
  theme_bg()

#p1_lnprice

summary(listings_clean$price_n)

p2_price <- ggplot(listings_clean, aes(price_n)) +
  geom_histogram(fill = color[1], color = color.outline, alpha = 0.8, size = 0.25) +
  ylab("count") +
  xlab("Price") +
  ggplot2::xlim(c(0,5000))+
  theme_bg()
#p2_price
```
Next, I turn to the *feature engineering:* choices. First, I inspect *missing values*. Here I drop variables if they  contain to many missing values and are not of importance for further analysis (e.g. calender updated and license). Other variables like 'bathrooms' or 'bedrooms', I impute with the help of descriptive variables like 'bathroom text' or approximate with the variable 'number of beds' and 'accommodates'. Some variables that contain only  few missing variables get the missing values replaced with the median of the non-missing values (e.g. n_days_since, review). 
```{r, echo=FALSE, include=FALSE}
#1) check for missing variables:
# calender updated and license many NAs, dropped beginning, drop columns when many missing not important
to_filter <- sapply(listings_clean, function(x) sum(is.na(x)))
to_filter[to_filter > 0]

#2a) NAs bathroom use bathrooms_text
listings_clean <- listings_clean %>%
  mutate(bathrooms = as.numeric(str_extract(bathrooms_text, "\\d+\\.?\\d*")),
         shared_bathroom = as.integer(str_detect(bathrooms_text, "shared")))

#2b) imput when few, assume at least 1 bath
listings_clean <- listings_clean %>%
  mutate(
    bathrooms =  ifelse(is.na(bathrooms), median(bathrooms, na.rm = T), bathrooms)) 

#3a) bedroom & number of beds NAs 
## use number of beds or impute from number of bed, if bed = 1 than put 1, either remain NA than check again number NAs: updating the 'bedrooms' variable based on the values in the 'beds' column
listings_clean <- listings_clean %>%
  mutate(bedrooms = if_else(beds %in% c(1, 2), 1, bedrooms)) %>%
  filter(bedrooms < 15) # there was one error 15 bedrooms 5 beds.

#3b) updating the 'beds' variable based on the values in the 'bedrooms'or 'accommodates' column
listings_clean <- listings_clean %>%
  mutate(
    beds = if_else(is.na(beds) & !is.na(bedrooms), bedrooms, beds),
    beds = if_else(is.na(beds) & is.na(bedrooms) & accommodates %in% c(1, 2), 1,
                   if_else(is.na(beds) & is.na(bedrooms) & accommodates > 2, 2, beds)),
    bedrooms = if_else(is.na(bedrooms) & is.na(beds) & accommodates %in% c(1, 2), 1,
                       if_else(is.na(bedrooms) & is.na(beds) & accommodates > 2, 2, bedrooms)))

#4) replace missing variables like reviews with zero, when no review + add flags
listings_clean <- listings_clean %>%
  mutate(
    flag_days_since=ifelse(is.na(n_days_since),1, 0),
    n_days_since =  ifelse(is.na(n_days_since), median(n_days_since, na.rm = T), n_days_since),
    flag_review_scores_rating=ifelse(is.na(review_scores_rating),1, 0),
    review_scores_rating =  ifelse(is.na(review_scores_rating), median(review_scores_rating, na.rm = T),
                                   review_scores_rating),
    flag_reviews_per_month=ifelse(is.na(reviews_per_month),1, 0),
    reviews_per_month =  ifelse(is.na(reviews_per_month), median(reviews_per_month, na.rm = T), reviews_per_month))

# CHECK AGAIN: where do we have missing variables now?
to_filter <- sapply(data, function(x) sum(is.na(x)))
to_filter[to_filter > 0] # should be 0 now 
```
In the following I consider th *functional form* of some of the predictors. However, these feature modifications are only relevant for the OLS (LASSO) model. The other two (machine-learning) models are non-parametric algorithms, which should be able to find interactions between variables and non-linear behavior. After visual and some basic regression analysis I add squared, cubic and log terms for the following variables: accommodates, beds, number_of_reviews, n_days_since, and review_scores_rating. 
```{r, echo=FALSE, include=FALSE}
#1) Feature engineering: functional form

## accommodates: look at distribution
summary(as.factor(listings_clean$accommodates))

listings_clean %>%
  group_by(accommodates) %>%
  summarise(mean_price = mean(price_n), min_price= min(price_n), max_price = max(price_n), n = n())

p5_accommodates <- ggplot(data = listings_clean, aes(x=accommodates, y=price_n)) +
  geom_point(size=1, colour=color[3], shape=16)+
  labs(x="Number of people accomodated",y="Price")+
  geom_smooth(method="lm", colour=color[1], se=FALSE)+
  theme_bg()

p5_accommodates

## Squares and further values to create
listings_clean <- listings_clean %>%
  mutate(accommodates2=accommodates^2, ln_accommodates=log(accommodates) ,
         ln_accommodates2=log(accommodates)^2)

## Regression: price and number of accommodates and squares
summary(lm(price_n ~ accommodates + accommodates2, data=listings_clean)) # not relevant?
## Regression: price and log number of accommodates
summary(lm(price_n ~ ln_accommodates , data=listings_clean)) # relevant 
## Regression: price and log squares number of accommodates  
summary(lm(price_n ~ ln_accommodates2, data=listings_clean))# relevant 
```

```{r, echo=FALSE, include=FALSE}
## Number of reviews: look at distribution
nreview_plot <- listings_clean %>%
  filter(number_of_reviews <100)

ggplot(nreview_plot, aes(number_of_reviews)) +
  geom_histogram(binwidth = 5, fill = color[1], color = color.outline, alpha = 0.8, size = 0.25) +
  ylab("") +
  xlab("N of reviews") +
  theme_bg()

## Logs and further values to create
listings_clean <- listings_clean %>%
  mutate(ln_number_of_reviews = log(number_of_reviews+1))

ggplot(listings_clean, aes(ln_number_of_reviews)) +
  geom_histogram(binwidth = 0.5, fill = color[1], color = color.outline, alpha = 0.8, size = 0.25) +
  ylab("") +
  xlab("Log N of reviews") +
  theme_bg()
```
```{r, echo=FALSE, include=FALSE}
## Beds: look at distribution
ggplot(listings_clean, aes(beds)) +
  geom_histogram(binwidth = 5, fill = color[1], color = color.outline, alpha = 0.8, size = 0.25) +
  ylab("") +
  xlab("N beds") +
  theme_bg()
#maybe best is to have log beds
listings_clean %>%
  group_by(beds) %>%
  summarise(mean_price = mean(price_n), min_price= min(price_n), max_price = max(price_n), n = n())
## Logs and further values to create
listings_clean <- listings_clean %>%
  mutate(ln_beds = log(beds),
         beds2=beds^2)
## Regression: price and log (beds)
summary(lm(price_n ~ ln_beds, data=listings_clean)) #relevant
## Regression: price and squared beds
summary(lm(price_n ~ beds2, data=listings_clean)) #relevant
```
```{r, echo=FALSE, include=FALSE}
## bathrooms: look at distribution
ggplot(listings_clean, aes(bathrooms)) +
  geom_histogram(binwidth = 0.5, fill = color[1], color = color.outline, alpha = 0.8, size = 0.25) +
  ylab("") +
  xlab("N of bathrooms") +
  theme_bg()
```
```{r, echo=FALSE, include=FALSE}
## create variables, measuring the time since: squared, cubic, logs
listings_clean <- listings_clean %>%
  mutate(
    ln_days_since = log(n_days_since+1),
    ln_days_since2 = log(n_days_since+1)^2,
    ln_days_since3 = log(n_days_since+1)^3 ,
    n_days_since2=n_days_since^2,
    n_days_since3=n_days_since^3,
    ln_review_scores_rating = log(review_scores_rating),
    ln_days_since=ifelse(is.na(ln_days_since),0, ln_days_since),
    ln_days_since2=ifelse(is.na(ln_days_since2),0, ln_days_since2),
    ln_days_since3=ifelse(is.na(ln_days_since3),0, ln_days_since3),
  )

# Check the effect
p6_lndays <- listings_clean %>%
  filter(listings_clean$price_n<=15000, ln_days_since>2)

ggplot(data = listings_clean, aes(x=ln_days_since , y=price_n)) +
  geom_point(size=1.5, colour=color[3], shape=4) +
  geom_smooth(method="loess", colour=color[1], se=F)+
  labs(x="Log number of days since first review",y="Log daily price")+
  theme_bg()

#-Inf values
summary(lm(price_n ~ ln_days_since + ln_days_since2 + ln_days_since3, data=listings_clean)) # not significant
```
```{r, echo=FALSE, include=FALSE}
## review score effect: look at distribution
ggplot(data = listings_clean, aes(x=review_scores_rating , y=price_n)) +
  geom_point(size=1.5, colour=color[3], shape=4) +
  geom_smooth(method="loess", colour=color[1], se=F)+
  labs(x="Review score",y="Daily price (USD)")+
  theme_bg()

#Create log of review scores
listings_clean <- listings_clean %>%
  mutate(ln_review_scores_rating = log(review_scores_rating))

# Regression:  price - num of review scores
summary(lm(price_n ~ review_scores_rating,data=listings_clean)) # relevant
# Regression: price - log num of review scores
#summary(lm(price_n ~ ln_review_scores_rating,data=listings_clean))
#leave as is
```

Last, I consider interactions of predictors. Again this is only relevant for the parametric OLS (LASSO) model.I assume interaction with f_property_type, f_room_type and accommodates and visualize those (see box plots appendix). The interaction follows the believe, the impact of room type on the response variable (e.g., price) varies depending on the specific property type, an interaction term can capture these differential effects. For example, the effect of upgrading to a higher room type might have different implications for prices in different property types (e.g., apartments vs. houses). Moreover, 


## interactions amenities???? (floowing london example)

```{r, echo=FALSE, include=FALSE}
# Interactions
##1) Box plot of price by room type
summary(as.factor(listings_clean$f_room_type))

p3_roomtype <- ggplot(data = listings_clean, aes(x = f_room_type, y = price_n)) +
  stat_boxplot(aes(group = f_room_type), geom = "errorbar", width = 0.3,
               color = c(color[2],color[1]), size = 0.5, na.rm=T)+
  geom_boxplot(aes(group = f_room_type),
               color = c(color[2],color[1]), fill = c(color[2],color[1]),
               size = 0.5, width = 0.6, alpha = 0.3, na.rm=T, outlier.shape = NA) +
  scale_y_continuous(expand = c(0.01,0.01),limits = c(0,2500), breaks = seq(0,2500,500)) +
  labs(x = "Room type",y = "Price (DKK)")+
  theme_bg()
#p3_roomtype
```


```{r, echo=FALSE, include=FALSE}
##2) Box plot of accommodates and price
summary(as.factor(listings_clean$accommodates))

p4_accomdates <- ggplot(listings_clean, aes(x = factor(accommodates), y = price_n))+
 geom_boxplot(aes(group = accommodates),
               color = c(color[2],color[1], color[3], color[4],color[5]), fill = c(color[2],color[1], color[3], color[4],color[5] ),
               size = 0.3, width = 0.8, alpha = 0.3, na.rm=T, outlier.shape = NA)  +
     stat_boxplot(aes(group = accommodates), geom = "errorbar", width = 0.8,
               color = c(color[2],color[1], color[3], color[4],color[5] ), size = 0.5, na.rm=T)+
    scale_color_manual(name="",
                     values=c(color[2],color[1],color[1],color[2],color[1],color[2])) +
  scale_fill_manual(name="",
                     values=c(color[2],color[1],color[3],color[4],color[1],color[2])) +
  labs(x = "Accomodates (Persons)",y = "Price (DKK)")+
  scale_y_continuous(expand = c(0.01,0.01), limits=c(0, 3500), breaks = seq(0,3500, 500))+
  theme_bg() +
  theme(legend.position = c(0.3,0.8)        )
#p4_accomdates
```


```{r, echo=FALSE, include=FALSE}
# Additional interactions of factors and dummies

X1  <- c("f_room_type*f_property_type",  "f_room_type*a_Childfriendly","a_Petfriendly*f_property_type")


amenities <-  grep("^a_.*", names(listings_clean), value = TRUE)
X2  <- c(paste("(f_property_type + f_room_type * (",paste(amenities, collapse=" + "),")"))

```


**Models:**
I chose to conduct the analysis using first an LASSO m 


* Have 3 different models and compare performance
* Argue for your choice of models

 **Model 1: OLS**
 
* Modelling Choices

 **Model 2: Random Forest**
 
* Modelling Choices

 **Model 3: Boosting Algorithm**
 
* Modelling Choices

**Model evaluation 1** 

**Task 2: Model evaluation 2 with mimicked live data**

* Please pick two dates , one before and one after lockdowns in that city.
* Carry out the exercise before the lockdown
* Take your selected model and use it on the post lockdown date
* Compare the predictive power of the model . Discuss briefly in the report


**Task 3: Model evaluation 3 Machine Learning and visualization:**

* Consider your ML model (RF or Boosting
* Explain features ’ contribution to predicted values on average , using Shapley values
* You shall use a SHAP method
* You may use graphs , but the emphasis is on the discussion part.
* This is worth relatively few points , do it only if everything else is already done
* extra add: graph on cv rmse?


## References (Adjust)
ChatGPT, Filter Excluded Property Types, November 21, 2023.
Retrieved from: https://chat.openai.com/share/c7ed8e6b-ffa8-46f0-97e4-672bff890d60

Békés,G., Kézdi,G.(2021).R, Python and Stata code for Data Analysis for Business, Economics, and Policy, ch13-used-cars-reg, GitHub repository, https://github.com/gabors-data-analysis/da_case_studies/tree/master/ch14-used-cars-log

Békés, G., & Kézdi, G. (2021). Data analysis for business, economics, and policy. Cambridge University Press, chapter 13.

## Appendix

```{r, figures-side, fig.show="hold", out.width="50%", echo =FALSE, warning=FALSE}
par(mar = c(4, 4, .1, .1))
p1_lnprice
p2_price
```

```{r, figures-side2, fig.show="hold", out.width="50%", echo =FALSE, warning=FALSE}
par(mar = c(4, 4, .1, .1))
p3_roomtype
p4_accomdates
```








################################################################################




```{r, echo=FALSE, include=FALSE}
#write.csv(listings_clean, paste0(data_out, "airbnb_cph_work_book.csv"), row.names = F)
```



```{r, echo=FALSE, include=FALSE}
### Descriptives of final data set

#umdrehen erst JUNE data !!! (pre and post lockdown)

# for task 1 we only need the data from September 2023 
listings_clean_SEP <- listings_clean[listings_clean$origin == "Sep 23",]

listings_clean <- listings_clean[listings_clean$origin == "Dec 22",]


# use Dec 22 later! 

N=nrow(listings_clean)

#####################################
# Look at some descriptive statistics
#####################################

#How is the average price changing in my district by `property_type`, `room_type` and the `bed_type`?
listings_clean %>%
  group_by(f_property_type, f_room_type) %>%
  dplyr::summarize(mean_price = mean(price_n, na.rm=TRUE))


#Hmisc::describe(listings_clean$price_n)


skimr::skim(listings_clean)
summary(listings_clean$price_n)
Hmisc::describe(listings_clean$price_n)
#describe(listings_clean$f_room_type)
#describe(listings_clean$f_property_type)
table(listings_clean$f_number_of_reviews)
```


```{r, echo=FALSE, include=FALSE}
### seperate data into holdout and work data set  


# fix here!!!!

# create a holdout set (20% of observations)
smp_size <- floor(0.2 * nrow(listings_clean))

# Set the random number generator
set.seed(123456)

# create ids:
# 1) seq_len: generate regular sequences
# 2) sample: select random rows from a table
holdout_ids <- sample(seq_len(nrow(listings_clean)), size = smp_size)
listings_clean$holdout <- 0
listings_clean$holdout[holdout_ids] <- 1

#Hold-out set Set
listings_holdout <- listings_clean %>% filter(holdout == 1)

#Working data set
listings_work <- listings_clean %>% filter(holdout == 0)

# see slide 56 again 
# use only ~80% as working data, rest is hold ou
# Split These 80% again into train and test (80/20)?
```


```{r,include=FALSE}
### seperate data into train and test data set  


# Basic Variables
basic_lev  <- c("accommodates", "beds", "f_property_type", "f_room_type", "n_days_since", "flag_days_since","neighbourhood_cleaned","bathroom")

reviews <- c("f_number_of_reviews","n_review_scores_rating", "flag_review_scores_rating")
# Higher orders
poly_lev <- c("accommodates2", "n_days_since2", "n_days_since3")

modellev1 <- paste0(" ~ ",paste(c(basic_lev,reviews,poly_lev,X1,X2,amenities),collapse = " + "))
```

```{r, include=FALSE, echo= FALSE}

### set up models:
### se OLS all models again

#OLS
##############################
#      cross validation      #
##############################

## N = 5
n_folds=5
# Create the folds
set.seed(123456)

folds_i <- sample(rep(1:n_folds, length.out = nrow(listings_work) ))
# Create results
model_results_cv <- list()

#for (i in (1:8)){
  model_name <- "modellev1"
 # model_pretty_name <- paste0("(",i,")")

  yvar <- "price_n"
  xvars <- c("accommodates + beds + f_property_type + f_room_type + n_days_since + flag_days_since + neighbourhood_cleansed + bathrooms + number_of_reviews + review_scores_rating + flag_review_scores_rating + accommodates2 + n_days_since2 + n_days_since3 + f_room_type*f_property_type + f_room_type*a_Childfriendly + a_Petfriendly*f_property_type + a_Parking + a_LongTermStay + a_Kitchen + a_Childfriendly + a_Laundry + a_OutdoorArea + a_Heating + a_Toiletry + a_TeaCoffee + a_Internet + a_Entertainment + a_Security + a_Selfcheckin + a_HomeOffice + a_Petfriendly")
  formula <-price_n ~ accommodates + beds + f_property_type + f_room_type + n_days_since + flag_days_since + neighbourhood_cleansed + bathrooms + number_of_reviews + review_scores_rating + flag_review_scores_rating + accommodates2 + n_days_since2 + n_days_since3 + f_room_type*f_property_type + f_room_type*a_Childfriendly + a_Petfriendly*f_property_type + a_Parking + a_LongTermStay + a_Kitchen + a_Childfriendly + a_Laundry + a_OutdoorArea + a_Heating + a_Toiletry + a_TeaCoffee + a_Internet + a_Entertainment + a_Security + a_Selfcheckin + a_HomeOffice + a_Petfriendly

  # Initialize values
  rmse_train <- c()
  rmse_test <- c()

  model_work_data <- lm(formula,data = listings_work)
  BIC <- BIC(model_work_data)
  nvars <- model_work_data$rank -1
  r2 <- summary(model_work_data)$r.squared

  # Do the k-fold estimation
  for (k in 1:n_folds) {
    test_i <- which(folds_i == k)
    # Train sample: all except test_i
    listings_train <- listings_work[-test_i, ]
    # Test sample
    listings_test <- listings_work[test_i, ]
    # Estimation and prediction
    model <- lm(formula,data = listings_train)
    prediction_train <- predict(model, newdata = listings_train)
    prediction_test <- predict(model, newdata = listings_test)

    # Criteria evaluation
    rmse_train[k] <- mse_lev(prediction_train, listings_train$price_ln)**(1/2)
    rmse_test[k] <- mse_lev(prediction_test, listings_test$price_ln)**(1/2)

  }

  
  model_results_cv[[model_name]] <- list(yvar=yvar,xvars=xvars,formula=formula,model_work_data=model_work_data,
                                         rmse_train = rmse_train,rmse_test = rmse_test,BIC = BIC,
                                         model_name = model_name, nvars = nvars, r2 = r2)

print(model_results_cv$modellev1)


t1 <- imap(model_results_cv,  ~{
  as.data.frame(.x[c("rmse_test", "rmse_train")]) %>%
    dplyr::summarise_all(.funs = mean) %>%
    mutate("model_name" = .y , "model_pretty_name" = .x[["model_name"]] ,
           "nvars" = .x[["nvars"]], "r2" = .x[["r2"]], "BIC" = .x[["BIC"]])
}) %>%
  bind_rows()
t1
column_names <- c("Model", "N predictors", "R-squared", "BIC", "Training RMSE",
                 "Test RMSE")
library(xtable)
output <- paste0(use_case_dir,"output/")

t14_2 <- t1 %>%
  select("model_pretty_name", "nvars", "r2" , "BIC", "rmse_train", "rmse_test")
colnames(t14_2) <- column_names
#print(xtable(t14_2, type = "latex", digits=c(0,0,0,2,0,2,2)), file = paste0(output, "ch14_table_fit_level.tex"),
 #     include.rownames=FALSE, booktabs=TRUE, floating = FALSE)

#### nur bei meheren Modellen?
# RMSE training vs test graph
#t1_levels <- t1 %>%
#  dplyr::select("nvars", "rmse_train", "rmse_test") %>%
  #gather(var,value, rmse_train:rmse_test) %>%
#  mutate(nvars2=nvars+1) %>%
 # mutate(var = factor(var, levels = c("rmse_train", "rmse_test"),
                  #    labels = c("RMSE Training","RMSE Test")))

#model_result_plot_levels <- ggplot(data = t1_levels,
                                 #  aes(x = factor(nvars2), y = value, color=factor(var), group = var)) +
 # geom_line(size=1,show.legend=FALSE, na.rm = TRUE) +
#  scale_color_manual(name="",
                     #values=c(color[2],color[1])) +
  #scale_y_continuous(name = "RMSE", limits = c(0, 1), breaks = seq(0,1, 02)) +
  #scale_x_discrete( name = "Number of coefficients", expand=c(0.01, 0.01)) +
 # geom_dl(aes(label = var),  method = list("last.points", dl.trans(x=x-1), cex=0.4)) +
  #scale_colour_discrete(guide = 'none') +
  #theme_bg()
#model_result_plot_levels


# OLS with dummies for area
# using model B
n_folds = 5

train_control <- trainControl(method = "cv", number = n_folds)
set.seed(1234)
system.time({
ols_model <- train(
  formula,
  data = listings_train,
  method = "lm",
  trControl = train_control
)
})

ols_model_coeffs <-  ols_model$finalModel$coefficients
ols_model_coeffs_df <- data.frame(
  "variable" = names(ols_model_coeffs),
  "ols_coefficient" = ols_model_coeffs
) %>%
  mutate(variable = gsub("`","",variable))

summary(ols_model)

```

```{r, echo=FALSE, include=FALSE, warning=F}
#Model 1: OLS(very similar to M7 vom slides singe this model was best in Terms of RMSE (test)). Use as external validity check & also try model 8 compar and Choose best

# Dp LASSO TO "SKIP" Modelling choice 

# Set lasso tuning parameters
n_folds = 5

train_control <- trainControl(method = "cv", number = n_folds)

tune_grid <- expand.grid("alpha" = c(1), "lambda" = seq(0.05, 1, by = 0.05))
# change! LAssO over all variables? 
set.seed(1234)


lasso_model <- caret::train(price_n ~ accommodates + beds + f_property_type + f_room_type + n_days_since + flag_days_since + neighbourhood_cleansed + bathrooms + number_of_reviews + review_scores_rating + flag_review_scores_rating + accommodates2 + n_days_since2 + n_days_since3 + f_room_type*f_property_type + f_room_type*a_Childfriendly + a_Petfriendly*f_property_type + a_Parking + a_LongTermStay + a_Kitchen + a_Childfriendly + a_Laundry + a_OutdoorArea + a_Heating + a_Toiletry + a_TeaCoffee + a_Internet + a_Entertainment + a_Security + a_Selfcheckin + a_HomeOffice + a_Petfriendly,
                      data = listings_work,
                      method = "glmnet",
                      preProcess = c("center", "scale"),
                      trControl = train_control,
                      tuneGrid = tune_grid,
                    na.action=na.exclude)

lasso_coeffs <- coef(lasso_model$finalModel, lasso_model$bestTune$lambda) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var = "variable") %>%
  rename(coefficient = `s1`)  # the column has a name "1", to be renamed

print(lasso_coeffs)

lasso_coeffs_nz<-lasso_coeffs %>%
  filter(coefficient!=0)
print(nrow(lasso_coeffs_nz))

summary(lasso_model)

# Evaluate model. CV error:
lasso_cv_rmse <- lasso_model$results %>%
  filter(lambda == lasso_model$bestTune$lambda) %>%
  dplyr::select(RMSE)
print(lasso_cv_rmse[1, 1])

```






















